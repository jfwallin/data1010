{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7, Module 3: Hierarchical Feature Extraction\n",
    "\n",
    "**Estimated time:** 10 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## **Opening: Putting It All Together**\n",
    "\n",
    "You've seen convolution in action:\n",
    "- **Module 0:** Tiny arrays with hand-designed filters\n",
    "- **Module 1:** Real images with classic filters (Sobel, blur, sharpen)\n",
    "- **Module 2:** Inside a real CNN, visualizing learned feature maps\n",
    "\n",
    "**Now the key question:** *Why does this architecture work so well?*\n",
    "\n",
    "The answer is **hierarchical feature extraction**â€”building complex patterns from simple ones, layer by layer.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ—ï¸ **The Hierarchy: From Pixels to Objects**\n",
    "\n",
    "### **The Big Picture**\n",
    "\n",
    "```\n",
    "Input Image (Raw Pixels)\n",
    "    â†“\n",
    "Layer 1-2: Edges & Gradients\n",
    "    (vertical lines, horizontal lines, diagonals, curves)\n",
    "    â†“\n",
    "Layer 3-4: Corners & Textures\n",
    "    (junctions, corners, stripes, dots, simple shapes)\n",
    "    â†“\n",
    "Layer 5-6: Object Parts\n",
    "    (eyes, ears, wheels, windows, doors, fur patterns)\n",
    "    â†“\n",
    "Layer 7+: Whole Objects\n",
    "    (faces, cars, animals, buildings)\n",
    "    â†“\n",
    "Final Dense Layers: Class Predictions\n",
    "    (\"Golden Retriever\", \"Sports Car\", \"Office Building\")\n",
    "```\n",
    "\n",
    "### **Why This Makes Sense**\n",
    "\n",
    "Think about how YOU recognize a dog:\n",
    "1. You see **edges** defining the outline\n",
    "2. You notice **textures** (fur, smooth nose)\n",
    "3. You identify **parts** (ears, snout, tail, paws)\n",
    "4. You combine parts into **\"dog\"**\n",
    "\n",
    "**CNNs do the exact same thing!** But they learn to do it automatically through training.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  **Comparison to Human Vision**\n",
    "\n",
    "This hierarchical structure mirrors how YOUR brain processes visual information!\n",
    "\n",
    "| Brain Region | Function | CNN Equivalent | What It Detects |\n",
    "|--------------|----------|----------------|------------------|\n",
    "| **V1** (Primary Visual Cortex) | First visual processing | Layers 1-2 | Edges, orientation, gradients |\n",
    "| **V2** (Secondary Visual) | Pattern combination | Layers 3-4 | Corners, textures, contours |\n",
    "| **V4** (Intermediate Visual) | Shape processing | Layers 5-6 | Object parts, shapes |\n",
    "| **IT** (Inferotemporal Cortex) | Object recognition | Layers 7+ | Whole objects, categories |\n",
    "\n",
    "### **The Parallel Is Not Coincidental**\n",
    "\n",
    "Early CNN researchers (1980s-1990s) were inspired by neuroscience research on cat visual cortex (Hubel & Wiesel, Nobel Prize 1981):\n",
    "- Found neurons that respond to specific edge orientations\n",
    "- Found hierarchical organization (simple cells â†’ complex cells â†’ hypercomplex cells)\n",
    "- This inspired the convolutional architecture!\n",
    "\n",
    "**Both biological and artificial systems discovered:** *Hierarchical feature extraction is the most efficient way to process visual information.*\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ’¡ **Why Hierarchical Learning Works**\n",
    "\n",
    "### **1. Compositionality**\n",
    "\n",
    "Complex features are built from simpler ones:\n",
    "- **Edges** combine to form **corners**\n",
    "- **Corners** combine to form **shapes**\n",
    "- **Shapes** combine to form **objects**\n",
    "\n",
    "**Analogy:** Like building with LEGO bricks\n",
    "- Small bricks â†’ Walls\n",
    "- Walls â†’ Rooms\n",
    "- Rooms â†’ Houses\n",
    "\n",
    "### **2. Reusability**\n",
    "\n",
    "Low-level features are reused across many objects:\n",
    "- **Vertical edges** appear in: buildings, doors, trees, poles, windows\n",
    "- **Circles** appear in: wheels, eyes, buttons, balls\n",
    "- **Textures** appear in: fur, grass, fabric, wood grain\n",
    "\n",
    "**Benefit:** The network doesn't need separate edge detectors for \"dog edges\" vs. \"car edges\"â€”one set of edge detectors works for everything!\n",
    "\n",
    "### **3. Translation Invariance**\n",
    "\n",
    "The same filter detects the same pattern **anywhere** in the image:\n",
    "- A vertical edge detector works whether the edge is:\n",
    "  - Top-left corner\n",
    "  - Center\n",
    "  - Bottom-right corner\n",
    "\n",
    "**Benefit:** Don't need to train separate detectors for each image location!\n",
    "\n",
    "### **4. Parameter Efficiency**\n",
    "\n",
    "Convolutional layers share parameters across the image:\n",
    "\n",
    "**Comparison:**\n",
    "- **Fully-connected layer** on 224Ã—224 RGB image:\n",
    "  - Input: 224 Ã— 224 Ã— 3 = **150,528 neurons**\n",
    "  - Hidden layer with 128 neurons: 150,528 Ã— 128 = **19,267,584 parameters**\n",
    "\n",
    "- **Convolutional layer** on same image:\n",
    "  - 32 filters, each 3Ã—3Ã—3\n",
    "  - Parameters: 32 Ã— 3 Ã— 3 Ã— 3 = **864 parameters**\n",
    "\n",
    "**Result:** CNNs are ~20,000x more parameter-efficient than fully-connected networks for images!\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”— **Connection to Lab 4: Hidden Layers**\n",
    "\n",
    "Remember Lab 4, where you learned about hidden layers transforming input space?\n",
    "\n",
    "### **Fully-Connected vs. Convolutional Layers**\n",
    "\n",
    "| Aspect | Fully-Connected (Lab 4) | Convolutional (Lab 7) |\n",
    "|--------|-------------------------|------------------------|\n",
    "| **What they do** | Transform entire input | Transform local patches |\n",
    "| **Parameters** | One weight per input neuron | Same filter applied everywhere |\n",
    "| **Best for** | Tabular data, global patterns | Images, local patterns |\n",
    "| **Example** | Iris classification | Image recognition |\n",
    "\n",
    "### **Key Similarity: Both Create Representations**\n",
    "\n",
    "- **Lab 4 hidden layer:** $(x, y) \\rightarrow (h_1, h_2, h_3, ...)$\n",
    "- **Lab 7 conv layer:** Image â†’ (edge map, texture map, shape map, ...)\n",
    "\n",
    "**Both are representation learning!** Just optimized for different data types.\n",
    "\n",
    "### **Hybrid Architectures**\n",
    "\n",
    "Real CNNs combine both:\n",
    "```\n",
    "Input Image (224Ã—224Ã—3)\n",
    "    â†“\n",
    "Convolutional Layers (learn spatial features)\n",
    "    â†“\n",
    "Flatten (convert to vector)\n",
    "    â†“\n",
    "Fully-Connected Layers (combine features for classification)\n",
    "    â†“\n",
    "Output (class probabilities)\n",
    "```\n",
    "\n",
    "**Why?** Conv layers are great at extracting features, but fully-connected layers are better at combining those features for the final decision.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”— **Connection to Lab 5: Embeddings**\n",
    "\n",
    "Remember Lab 5, where you learned how words become vectors that capture meaning?\n",
    "\n",
    "### **CNNs Create Image Embeddings**\n",
    "\n",
    "The final convolutional layers create **image embeddings**:\n",
    "- High-dimensional vectors (512, 1024, or 2048 dimensions)\n",
    "- Capture semantic content of the image\n",
    "- Similar images â†’ similar embeddings\n",
    "\n",
    "**Example:**\n",
    "- All dog images cluster together in embedding space\n",
    "- All car images cluster together\n",
    "- Golden Retriever and Labrador are closer than Golden Retriever and Car\n",
    "\n",
    "### **Applications of Image Embeddings**\n",
    "\n",
    "1. **Image search:** Find similar images\n",
    "2. **Transfer learning:** Use CNN features for new tasks\n",
    "3. **Multimodal AI:** Connect text and images (CLIP, DALL-E)\n",
    "4. **Face recognition:** Compare face embeddings\n",
    "\n",
    "**The connection:**\n",
    "- Lab 5: Text â†’ embeddings (capture meaning)\n",
    "- Lab 7: Images â†’ embeddings (capture visual content)\n",
    "- Modern AI: Both â†’ unified representation space!\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”— **Connection to Lab 6: Saliency**\n",
    "\n",
    "### **How Saliency and Feature Maps Work Together**\n",
    "\n",
    "**Feature maps (Lab 7):** Show what patterns each layer detects\n",
    "- Layer 1: Edge map shows where edges are\n",
    "- Layer 3: Texture map shows where textures are\n",
    "- Layer 6: Part map shows where object parts are\n",
    "\n",
    "**Saliency (Lab 6):** Shows which detected patterns matter for the prediction\n",
    "- \"The dog's ears are important\" â†’ High saliency on ear feature map\n",
    "- \"The background grass is not important\" â†’ Low saliency on grass texture map\n",
    "\n",
    "**Together:**\n",
    "1. Convolution extracts hierarchical features\n",
    "2. Final layers combine features for prediction\n",
    "3. Saliency reveals which features drove the decision\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Image of dog\n",
    "  â†’ Conv layers detect: edges, fur texture, ear shapes, snout shape\n",
    "  â†’ Classifier predicts: \"Golden Retriever\"\n",
    "  â†’ Saliency reveals: Ears and snout were most important\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”— **Connection to Lab 3: Activation Functions**\n",
    "\n",
    "Remember Lab 3, where you learned about ReLU, sigmoid, and other activation functions?\n",
    "\n",
    "### **Activation Functions in CNNs**\n",
    "\n",
    "**Standard CNN layer:**\n",
    "```python\n",
    "# Convolution (linear operation)\n",
    "feature_map = conv2d(input, filter)\n",
    "\n",
    "# Activation function (nonlinearity)\n",
    "activated = relu(feature_map)\n",
    "```\n",
    "\n",
    "### **Why Both Are Needed**\n",
    "\n",
    "**Without activation functions:**\n",
    "- Stack of conv layers = one big linear transformation\n",
    "- Can only learn linear decision boundaries\n",
    "- Cannot detect complex patterns (curves, textures, shapes)\n",
    "\n",
    "**With ReLU:**\n",
    "- Each layer: Convolution â†’ ReLU\n",
    "- ReLU introduces nonlinearity: $f(x) = \\max(0, x)$\n",
    "- Enables learning complex, hierarchical patterns\n",
    "\n",
    "**Just like Lab 3:**\n",
    "- Lab 3: Dense layer + ReLU â†’ Warped feature space\n",
    "- Lab 7: Conv layer + ReLU â†’ Hierarchical feature detection\n",
    "\n",
    "**Same principle, different application!**\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŒ **Real-World Applications**\n",
    "\n",
    "Hierarchical CNNs power many technologies you use every day:\n",
    "\n",
    "### **1. Face Recognition (Your Phone)**\n",
    "- Early layers: Edge detection (face outline)\n",
    "- Mid layers: Facial features (eyes, nose, mouth)\n",
    "- Deep layers: Unique face patterns\n",
    "- Output: Face embedding for comparison\n",
    "\n",
    "### **2. Medical Imaging**\n",
    "- Early layers: Tissue boundaries\n",
    "- Mid layers: Organ shapes, textures\n",
    "- Deep layers: Pathology patterns (tumors, lesions)\n",
    "- Output: Diagnosis (benign vs. malignant)\n",
    "\n",
    "### **3. Autonomous Vehicles**\n",
    "- Early layers: Lane markings, road edges\n",
    "- Mid layers: Vehicles, pedestrians, signs\n",
    "- Deep layers: Scene understanding (intersection, highway, parking lot)\n",
    "- Output: Driving decisions\n",
    "\n",
    "### **4. Content Moderation**\n",
    "- Early layers: Text, faces, objects\n",
    "- Mid layers: Scenes, contexts\n",
    "- Deep layers: Violating content patterns\n",
    "- Output: Safe/unsafe classification\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“ **Questions (Q16-Q19)**\n",
    "\n",
    "Record your answers in the **Answer Sheet**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q16. Why does hierarchical feature extraction make sense for object recognition?**\n",
    "\n",
    "*Hint: Objects are made of parts, parts are made of shapes, shapes are made of edges. How does this match the CNN hierarchy?*\n",
    "\n",
    "**Record your answer in the Answer Sheet.**\n",
    "\n",
    "---\n",
    "\n",
    "### **Q17. How is a CNN's Layer 1 similar to the human visual cortex area V1?**\n",
    "\n",
    "*Hint: Look at the comparison table. What do both detect? Why would evolution and machine learning arrive at similar solutions?*\n",
    "\n",
    "**Record your answer in the Answer Sheet.**\n",
    "\n",
    "---\n",
    "\n",
    "### **Q18. What advantage does parameter sharing give CNNs?**\n",
    "\n",
    "*Hint: Compare the number of parameters for fully-connected vs. convolutional layers (see the example calculation). What does this enable?*\n",
    "\n",
    "**Record your answer in the Answer Sheet.**\n",
    "\n",
    "---\n",
    "\n",
    "### **Q19. Thinking back to Lab 4: How are convolutional layers similar to hidden layers? How are they different?**\n",
    "\n",
    "*Hint: Both create new representations. But one looks at the entire input globally, while the other focuses on local spatial patterns. What data type is each best suited for?*\n",
    "\n",
    "**Record your answer in the Answer Sheet.**\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Module 3 Complete!\n",
    "\n",
    "You now understand:\n",
    "- **The hierarchical structure of CNNs** (edges â†’ textures â†’ shapes â†’ objects)\n",
    "- **Why it works** (compositionality, reusability, translation invariance, efficiency)\n",
    "- **Parallels to human vision** (V1 â†’ V2 â†’ V4 â†’ IT cortex)\n",
    "- **Connections to previous labs** (hidden layers, embeddings, saliency, activation functions)\n",
    "- **Real-world applications** (face recognition, medical imaging, autonomous vehicles)\n",
    "\n",
    "**Key insight:**\n",
    "> Hierarchical feature extractionâ€”building complex patterns from simple onesâ€”is the fundamental principle behind both biological and artificial vision systems.\n",
    "\n",
    "**Ready to train your own CNN from scratch?**\n",
    "\n",
    "Move on to **Module 4: Training a CNN on MNIST**, where you'll build and train a simple CNN to recognize handwritten digitsâ€”watching it learn edge detectors, shape detectors, and digit classifiers in just a few minutes!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
