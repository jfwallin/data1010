{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38445b55",
   "metadata": {},
   "source": "# Lab 5, Module 1: Word Embeddings & Vector Arithmetic\n\n**Estimated time:** 25 minutes\n\n---\n\n## From Tiny to Massive: Scaling Up Embeddings\n\nIn Module 0, you built an embedding system from 27 sentences and 92 words. That was enough to see the core idea: words that appear in similar contexts get similar vectors.\n\n**Now let's scale up.**\n\nIn this module, you'll work with **GloVe** (Global Vectors for Word Representation), a professional embedding model trained on:\n- **6 billion tokens** from Wikipedia and web text\n- **400,000 vocabulary words**\n- **50-dimensional vectors** (much more compact than our 92√ó92 matrix!)\n\nThese embeddings capture fascinating patterns in language, including:\n- Which dimensions correspond to concepts like \"science-ness\" or \"formality\"\n- **Vector arithmetic** that solves analogies: *paris - france + italy ‚âà rome*\n- Relationships between word families, tenses, and grammatical forms\n\n**What you'll explore:**\n1. Load pre-trained GloVe word vectors\n2. Examine individual word embeddings\n3. Investigate what individual dimensions capture\n4. Use vector arithmetic to solve analogies\n5. Try your own custom analogies\n\nLet's dive in!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7653682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell:\n",
    "#   ‚Ä¢ Loads a small, free word embedding model (GloVe)\n",
    "#   \n",
    "#\n",
    "# NOTE: The first time you run this, it will download the model (~70MB),\n",
    "#       which may take up to a minute in Colab.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import gensim.downloader as api\n",
    "except ImportError:\n",
    "    !pip install -q gensim\n",
    "    import gensim.downloader as api\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26798350",
   "metadata": {},
   "source": "### Loading Pre-Trained Embeddings\n\nThe gensim downloader will load a large set of words that have already been embedded into vector representations. \n\n**This happens automatically** when you run the cell above. The first time, it downloads ~70MB (takes about a minute). After that, it's cached.\n\nOnce loaded, you'll see:\n- **Vocabulary size:** ~400,000 words\n- **Vector dimension:** 50 dimensions per word\n\nCompare this to Module 0:\n- Your tiny system: 92 words, 92 dimensions\n- GloVe: 400,000 words, 50 dimensions!\n\nGloVe uses dimensionality reduction (similar to PCA) to compress the co-occurrence information into just 50 numbers per word while preserving the important relationships.\n\n---\n\n## üìù Question 7 (Observation)\n\n**Q7.** How many dimensions does each GloVe word vector have? How does this compare to Module 0's co-occurrence embeddings?\n\n*Record your answer in the answer sheet.*\n\n---"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c66542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#  Module 1 ‚Äî Activity 0: Word-level Embedding\n",
    "#  DATA 1010 ‚Äì Artificial Intelligence in Action\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load a pre-trained word embedding model\n",
    "# -----------------------------\n",
    "# Check if the model is already loaded to avoid reloading\n",
    "if 'w2v' not in locals():\n",
    "    print(\"Loading GloVe word vectors (glove-wiki-gigaword-50)...\")\n",
    "    w2v = api.load(\"glove-wiki-gigaword-50\")  # 50-dimensional GloVe\n",
    "    print(\"Model loaded!\")\n",
    "    print(f\"Vocabulary size: {len(w2v.index_to_key):,} words\")\n",
    "    print(f\"Vector dimension: {w2v.vector_size} dimensions\\n\")\n",
    "else:\n",
    "    print(\"GloVe word vectors (w2v) already loaded.\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91df6a9e",
   "metadata": {},
   "source": [
    "### Let's take a look at a few of the words and how they are represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f015e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.set_printoptions(precision=3,linewidth=60)\n",
    "w = \"galaxy\"\n",
    "print(f\"word: {w:20s} \")\n",
    "print(f\"Length of embedding: {len(w2v[w])}\")\n",
    "print(f\"embedding: \\n{ w2v[w]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de17d33b",
   "metadata": {},
   "source": "### Visualizing the Dimensions\n\nNow let's look at how different words are represented across the 50 dimensions.\n\nWe'll plot the vectors of a few words and see how they look on a 2D chart. Each line represents the embedding of a different word. \n\n**What to look for:** Notice the peak around parameter 30. That value seems to be higher for everyday words like \"person\" and \"table\" than for scientific words like \"galaxy\" and \"atom\".\n\nCould individual dimensions capture specific concepts? Let's investigate!\n\n---\n\n## üìù Question 8 (Observation)\n\n**Q8.** Looking at the dimension plots for \"galaxy\", \"person\", \"table\", and \"atom\", what do you notice about parameter 30?\n\n*Hint: Which words have high values? Which have low values?*\n\n*Record your answer in the answer sheet.*\n\n---"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce52781",
   "metadata": {},
   "outputs": [],
   "source": [
    "science_words =  [\"galaxy\", \"person\", \"table\", \"atom\"]\n",
    "x = list(range(50))\n",
    "np.set_printoptions(precision=3,linewidth=60)\n",
    "for w in science_words:\n",
    "    print(f\"word: {w:20s} \")\n",
    "    y = w2v[w]\n",
    "    plt.plot(x,y, label=w)\n",
    "    \n",
    "plt.annotate('Peak', xy=(30, 2), xytext=(25, 2.5),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             ha='right', va='bottom')\n",
    "plt.legend ( )\n",
    "plt.xlabel( \"Dimension\")\n",
    "plt.ylabel(\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ecf337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f91960a",
   "metadata": {},
   "source": "### Let's Explore Parameter 33\n\nWe noticed something interesting in the plot above. Now let's investigate more systematically.\n\n**Experiment:**\n1) Take a bunch of science words - find all their vectors and average them\n2) Take a bunch of non-science words - find all their vectors and average them\n3) Subtract the non-science from the science, and plot the results\n\n**Question:** Will we find a dimension that consistently captures \"science-ness\"?\n\nLet's find out!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d924228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "science_words = science_words + [\"galaxy\", \"atom\", \"molecule\", \"quantum\",\"telescope\", \"cell\", \"nucleus\", \"research\", \"experiment\"]\n",
    "nonscience_words = [\"cat\", \"dog\", \"pizza\", \"music\", \"tree\", \"happy\", \"running\", \"house\"]\n",
    "\n",
    "\n",
    "science_average = np.zeros(50)\n",
    "science_ct = 0\n",
    "for w in science_words:\n",
    "  word_vector = w2v[w]\n",
    "  science_average = science_average + np.array(word_vector)\n",
    "  science_ct = science_ct + 1\n",
    "science_average = science_average / science_ct\n",
    "  \n",
    "nonscience_average = np.zeros(50)\n",
    "nonscience_ct = 0\n",
    "for w in nonscience_words:\n",
    "  word_vector = w2v[w]\n",
    "  nonscience_average = nonscience_average + np.array(word_vector)\n",
    "  nonscience_ct = nonscience_ct + 1\n",
    "nonscience_average = nonscience_average / nonscience_ct\n",
    "  \n",
    "science_displacement = science_average - nonscience_average\n",
    "x = np.array(list(range(50)))\n",
    "\n",
    "plt.plot(x,science_displacement,\"*\")\n",
    "plt.xlabel(\"embedding parameter\")\n",
    "plt.ylabel(\"displacement from non-science words to science words\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ccd624",
   "metadata": {},
   "source": [
    "### What happened?\n",
    "\n",
    "There are clear differences between science words and non-science words.  However, the biggest displayment seems to be parameter 33 where the diference science words average about 1.7 lower than non-science words.\n",
    "\n",
    "Let's explore this with some other science words and see what happens with parameter 33 and a few other random parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b7c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_science_words = [\"economics\", \"microbiology\",\"zoology\",\"biochemistry\",\"oceanography\",\"science\",\"chemistry\",\"physics\",\"biology\",\"meteorology\",\"geology\",\"mathematics\",\"astronomy\",\"astrophysics\"]\n",
    "\n",
    "p1 = np.random.randint(32)\n",
    "p2 = np.random.randint(16) + 34\n",
    "\n",
    "print(f\"  word                  P: 33     P: {p1:02d}    P:{p2:02d}\")\n",
    "wlist = []\n",
    "for w in new_science_words:\n",
    "  wa = w2v[w]\n",
    "  wlist.append(wa)\n",
    "  print(f\"{w:20s} {wa[33]-nonscience_average[33]:>8.3f}  \" \\\n",
    "    + f\"{wa[p1]-nonscience_average[p1]:>8.3f} \" \\\n",
    "    + f\"{wa[p2]-nonscience_average[p2]:>8.3f} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd061e76",
   "metadata": {},
   "source": "### What Did We Find?\n\n**Key observation:** Parameter 33 shows a clear pattern. Science words consistently have LOWER values than non-science words at dimension 33.\n\n- Physics: very \"science-ey\" (P33 ‚âà -2.6)\n- Economics: moderately \"science-ey\" (P33 ‚âà -1.5)\n- Most science fields: negative displacement\n\n**But is parameter 33 literally \"science-ness\"?**\n\nNo. The actual meaning of parameter 33 is more complex and abstract. It just happens to correlate somewhat with what we humans call \"science.\" \n\nThe model learned this dimension automatically by analyzing billions of words. It discovered that certain words cluster together in usage patterns, and parameter 33 captures part of that structure.\n\n**The important insight:** Even though we can't perfectly interpret each dimension, they collectively encode meaningful semantic relationships.\n\n---\n\n## üìù Question 9 (Analysis)\n\n**Q9.** Why do science words have lower values at parameter 33 compared to non-science words? What does this dimension seem to capture?\n\n*Think about: Is it exactly \"science\"? Or something more abstract that correlates with science?*\n\n*Record your answer in the answer sheet.*\n\n---"
  },
  {
   "cell_type": "markdown",
   "id": "ca55ba71",
   "metadata": {},
   "source": "# Vector Arithmetic & Analogies\n\n## The Magic of Embedding Geometry\n\nHere's where embeddings get really interesting. Because words are represented as vectors in a geometric space, we can do **arithmetic** on them!\n\n**The key insight:** Relationships between words are preserved as directional patterns in the embedding space.\n\nFor example:\n- The direction from \"france\" to \"paris\" (country ‚Üí capital)\n- Should be similar to the direction from \"italy\" to \"rome\"\n\nSo if we compute: **paris - france + italy**, we should get a vector close to **rome**!\n\n## How Analogies Work\n\nWe use analogies of the form: **A ‚àí B + C  ‚âà  ?**\n\nwhere:\n- **A** is a *changed* form (plural, past, comparative, capital, etc.)\n- **B** is the *base* form (singular, present, base adjective, country, etc.)\n- **C** is a *new base* you want to transform\n\nExamples of relationships that work well:\n- **Country ‚Üî Capital:** paris - france + italy ‚âà rome  \n- **Comparatives:** smaller - small + big ‚âà bigger  \n- **Verb tenses:** walked - walk + swim ‚âà swam  \n- **Pluralization:** children - child + person ‚âà people  \n- **Family roles:** aunt - uncle + brother ‚âà sister  \n\n---\n\n## üìù Question 10 (Prediction)\n\nBefore running the code below, make a prediction:\n\n**Q10.** What word should complete this analogy: **paris - france + italy = ?**\n\n*Think about the relationship between paris and france. Apply that same relationship to italy.*\n\n**Write your prediction in the answer sheet, then run the code to check!**\n\n---"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac74c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#  Module 2 ‚Äî Activity 3: Vector Arithmetic & Analogies\n",
    "#  DATA 1010 ‚Äì Artificial Intelligence in Action\n",
    "# ============================================================\n",
    "\n",
    "# This cell:\n",
    "#   ‚Ä¢ Demonstrates classic analogies like: king - man + woman ‚âà queen\n",
    "#   ‚Ä¢ Lets you try your own word analogies\n",
    "#\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load a pre-trained word embedding model\n",
    "# -----------------------------\n",
    "# Check if the model is already loaded to avoid reloading\n",
    "if 'w2v' not in locals():\n",
    "    print(\"Make sure to execute the top of the notebook before trying this cell.\")\n",
    "    exit()\n",
    "else:\n",
    "    print(\"GloVe word vectors (w2v) already loaded.\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Helper function: show analogy\n",
    "# -----------------------------\n",
    "def show_analogy(word_a, word_b, word_c, topn=5):\n",
    "    \"\"\"\n",
    "    Compute:  word_a - word_b + word_c  ‚âà  ?\n",
    "    and print the top similar words.\n",
    "    \"\"\"\n",
    "    print(\"===============================================\")\n",
    "    print(f\"Analogy:  {word_a}  -  {word_b}  +  {word_c}  ‚âà  ?\")\n",
    "    print(\"===============================================\")\n",
    "\n",
    "    # Check vocabulary\n",
    "    for w in [word_a, word_b, word_c]:\n",
    "        if w not in w2v:\n",
    "            print(f\"  ‚Ä¢ The word '{w}' is not in the model vocabulary.\")\n",
    "            return\n",
    "\n",
    "    # Vector arithmetic\n",
    "    result_vec = w2v[word_a] - w2v[word_b] + w2v[word_c]\n",
    "\n",
    "    # Find most similar words to result_vec\n",
    "    sims = w2v.similar_by_vector(result_vec, topn=topn)\n",
    "\n",
    "    for rank, (word, score) in enumerate(sims, start=1):\n",
    "        print(f\"{rank}. {word:15s}  (cosine similarity: {score:.4f})\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Reliable Example Analogies\n",
    "# -----------------------------\n",
    "print(\"### Reliable Analogy Examples ###\\n\")\n",
    "\n",
    "# Capital‚ÄìCountry (A = capital, B = country, C = new country)\n",
    "show_analogy(\"paris\",   \"france\",  \"italy\")     # ‚Üí rome\n",
    "show_analogy(\"berlin\",  \"germany\", \"spain\")     # ‚Üí madrid\n",
    "\n",
    "# Comparatives (A = comparative, B = base adj, C = new base adj)\n",
    "show_analogy(\"smaller\", \"small\",   \"big\")       # ‚Üí bigger\n",
    "show_analogy(\"colder\",  \"cold\",    \"warm\")      # ‚Üí warmer\n",
    "\n",
    "# Verb tenses (A = past, B = present, C = new present)\n",
    "show_analogy(\"walked\",  \"walk\",    \"swim\")      # ‚Üí swam\n",
    "show_analogy(\"made\",    \"make\",    \"think\")     # ‚Üí thought\n",
    "\n",
    "# Plurals (A = plural, B = singular, C = new singular)\n",
    "show_analogy(\"children\",\"child\",   \"person\")    # ‚Üí people\n",
    "show_analogy(\"dogs\",    \"dog\",     \"cat\")       # ‚Üí cats\n",
    "\n",
    "# Family roles (A = female, B = male, C = new male)\n",
    "show_analogy(\"aunt\",    \"uncle\",   \"brother\")   # ‚Üí sister\n",
    "show_analogy(\"mother\",  \"father\",  \"son\")       # ‚Üí daughter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066954a3",
   "metadata": {},
   "source": "### What Makes Analogies Work (and Why Some Fail)\n\n**This model is particularly good at:**\n- Capital‚Äìcountry relationships\n- Singular‚Äìplural transformations\n- Present‚Äìpast verb forms\n- Base‚Äìcomparative adjectives\n- Family relationships (gender pairs)\n\n**It is not very good at:**\n- Animal ‚Üí sound (e.g., dog ‚Üí bark)\n- Abstract \"vibes\" (e.g., cozy, spooky)\n- Pop culture or memes\n- Very specific or rare relationships\n\n**Why?** Analogies work when the relationship is represented as a consistent directional pattern across many examples in the training data. If a relationship isn't encoded consistently in the corpus, the model won't capture it.\n\nSo if your custom analogy fails, it doesn't mean you did it wrong‚Äîit often means the relationship isn't represented as a simple line in this embedding space.\n\n---\n\n## üìù Questions 11-15 (Analysis & Experimentation)\n\n**Q11.** After running the analogy code, was your prediction for Q10 correct? What was the top result?\n\n**Q12.** Try your own analogy in the interactive section below. Record your input (A, B, C) and the top result. Did it work as expected?\n\n**Q13.** Which type of analogy works best in this model: capital-country, comparative adjectives, verb tenses, or family relationships? Look at the cosine similarity scores.\n\n**Q14.** Why do you think some analogies (like animal ‚Üí sound) don't work well in word embeddings?\n\n*Hint: Think about how often these relationships appear in similar sentence contexts.*\n\n**Q15.** How does vector arithmetic (like king - man + woman = queen) demonstrate that embeddings capture meaning relationships rather than just word similarity?\n\n*Think about: What does the direction from \"man\" to \"king\" represent? Why does adding that direction to \"woman\" give \"queen\"?*\n\n*Record your answers in the answer sheet.*\n\n---\n\nNow try your own analogy below!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb4a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 4. Try your own analogy\n",
    "# -----------------------------\n",
    "print(\"Now try your own analogy!\")\n",
    "print(\"Enter three words to compute:  A - B + C  ‚âà  ?\")\n",
    "print(\"Example:  A = king, B = man, C = woman\\n\")\n",
    "\n",
    "word_a = input(\"Enter word A: \").strip().lower()\n",
    "word_b = input(\"Enter word B: \").strip().lower()\n",
    "word_c = input(\"Enter word C: \").strip().lower()\n",
    "\n",
    "show_analogy(word_a, word_b, word_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "64d433f9",
   "metadata": {},
   "outputs": [],
   "source": "## ‚úÖ Module 1 Complete!\n\nExcellent work! You've explored pre-trained word embeddings and discovered some fascinating patterns:\n\n- **GloVe vectors** are trained on billions of words but use only 50 dimensions\n- **Individual dimensions** capture abstract concepts (like the \"science-ness\" of parameter 33)\n- **Vector arithmetic** solves analogies: paris - france + italy ‚âà rome\n- **Geometric relationships** encode meaning: similar directions = similar relationships\n- **Not all analogies work** - only relationships consistently represented in training data\n\n**What's next?**\n\nIn Module 0, you embedded **individual words**.\nIn Module 1, you explored **word-level relationships**.\n\n**In Module 2**, you'll embed **entire sentences** and build a semantic search engine that finds documents by meaning, not just keywords. This is the foundation of modern information retrieval systems and RAG (Retrieval-Augmented Generation).\n\n**Ready?** Move on to **Module 2: Sentence Embeddings & Semantic Search**!"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orbits",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}