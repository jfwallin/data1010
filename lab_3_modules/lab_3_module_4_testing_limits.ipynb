{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 - Module 4: Testing the Perceptron's Limits\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Test a perceptron on non-linearly separable problems (XOR and circles)\n",
    "- Understand why a single perceptron fails on these patterns\n",
    "- Connect this limitation to the need for multi-layer neural networks\n",
    "- Recognize that activation functions alone don't solve everything\n",
    "\n",
    "**Time:** ~15 minutes\n",
    "\n",
    "---\n",
    "\n",
    "**From Module 3:** You successfully used perceptrons to classify linearly separable datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection to Previous Modules\n",
    "\n",
    "**Module 0:** You discovered that XOR and circular patterns **cannot** be separated by straight lines\n",
    "\n",
    "**Module 1:** Activation functions warp space and create curved boundaries\n",
    "\n",
    "**Module 2:** Different activations have different properties\n",
    "\n",
    "**Module 3:** You built perceptrons and successfully classified linearly separable data\n",
    "\n",
    "**Today's Key Question:** \n",
    "Can a perceptron (weighted sum â†’ activation) solve the XOR and circle problems?\n",
    "\n",
    "**Spoiler:** No! And understanding why is crucial for understanding neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup: Reload the Impossible Datasets\n",
    "\n",
    "Let's bring back the XOR and circular patterns from Module 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import FloatSlider, Dropdown, interact, VBox, HTML\n",
    "from IPython.display import display\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Dataset 1: XOR pattern (four corners)\n",
    "n_per_corner = 25\n",
    "XOR_corners = np.array([\n",
    "    [-1.5, -1.5], [1.5, -1.5],  # Class 0 (bottom corners)\n",
    "    [-1.5, 1.5], [1.5, 1.5]      # Class 1 (top corners)\n",
    "])\n",
    "X_xor = []\n",
    "y_xor = []\n",
    "for i, corner in enumerate(XOR_corners):\n",
    "    points = np.random.randn(n_per_corner, 2) * 0.3 + corner\n",
    "    X_xor.append(points)\n",
    "    # XOR pattern: corners 0,3 are class 0, corners 1,2 are class 1\n",
    "    label = 0 if i % 3 == 0 else 1\n",
    "    y_xor.append(np.ones(n_per_corner) * label)\n",
    "X_xor = np.vstack(X_xor)\n",
    "y_xor = np.hstack(y_xor)\n",
    "\n",
    "# Dataset 2: Concentric circles\n",
    "n_per_circle = 50\n",
    "# Inner circle (class 0)\n",
    "angles_inner = np.random.uniform(0, 2*np.pi, n_per_circle)\n",
    "radius_inner = np.random.uniform(0.3, 0.8, n_per_circle)\n",
    "X_circle_inner = np.column_stack([\n",
    "    radius_inner * np.cos(angles_inner),\n",
    "    radius_inner * np.sin(angles_inner)\n",
    "])\n",
    "# Outer ring (class 1)\n",
    "angles_outer = np.random.uniform(0, 2*np.pi, n_per_circle)\n",
    "radius_outer = np.random.uniform(1.5, 2.2, n_per_circle)\n",
    "X_circle_outer = np.column_stack([\n",
    "    radius_outer * np.cos(angles_outer),\n",
    "    radius_outer * np.sin(angles_outer)\n",
    "])\n",
    "X_circles = np.vstack([X_circle_inner, X_circle_outer])\n",
    "y_circles = np.hstack([np.zeros(n_per_circle), np.ones(n_per_circle)])\n",
    "\n",
    "print(\"âœ“ Two challenging datasets loaded!\")\n",
    "print(\"\\nDataset 1: XOR Pattern\")\n",
    "print(\"Dataset 2: Concentric Circles\")\n",
    "print(\"\\nRemember from Module 0: No straight line can separate these patterns.\")\n",
    "\n",
    "# Activation functions\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
    "\n",
    "def tanh(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def step(z):\n",
    "    return (z > 0).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize the Challenge\n",
    "\n",
    "Let's remind ourselves what these patterns look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6), dpi=100)\n",
    "\n",
    "# XOR pattern\n",
    "ax1.scatter(X_xor[y_xor == 0, 0], X_xor[y_xor == 0, 1],\n",
    "           c='blue', s=80, alpha=0.6, label='Class 0', edgecolors='k', linewidths=1.5)\n",
    "ax1.scatter(X_xor[y_xor == 1, 0], X_xor[y_xor == 1, 1],\n",
    "           c='red', s=80, alpha=0.6, label='Class 1', edgecolors='k', linewidths=1.5)\n",
    "ax1.set_xlabel('xâ‚', fontsize=13)\n",
    "ax1.set_ylabel('xâ‚‚', fontsize=13)\n",
    "ax1.set_title('Dataset 1: XOR Pattern\\n(Four Corners)', fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_aspect('equal')\n",
    "ax1.set_xlim(-3, 3)\n",
    "ax1.set_ylim(-3, 3)\n",
    "\n",
    "# Circles\n",
    "ax2.scatter(X_circles[y_circles == 0, 0], X_circles[y_circles == 0, 1],\n",
    "           c='blue', s=80, alpha=0.6, label='Class 0 (Inner)', edgecolors='k', linewidths=1.5)\n",
    "ax2.scatter(X_circles[y_circles == 1, 0], X_circles[y_circles == 1, 1],\n",
    "           c='red', s=80, alpha=0.6, label='Class 1 (Outer)', edgecolors='k', linewidths=1.5)\n",
    "ax2.set_xlabel('xâ‚', fontsize=13)\n",
    "ax2.set_ylabel('xâ‚‚', fontsize=13)\n",
    "ax2.set_title('Dataset 2: Concentric Circles\\n(Inner vs Outer Ring)', fontsize=13, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_aspect('equal')\n",
    "ax2.set_xlim(-3, 3)\n",
    "ax2.set_ylim(-3, 3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nChallenge: Try to get the perceptron to classify these patterns.\")\n",
    "print(\"Adjust wâ‚, wâ‚‚, b, and try different activations.\")\n",
    "print(\"Can you get better than 50% accuracy (random guessing)?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interactive: Try to Classify XOR and Circles\n",
    "\n",
    "**Your task:** Try to find perceptron parameters that work for these datasets.\n",
    "\n",
    "**Prediction:** You won't be able to! But it's important to try and see why.\n",
    "\n",
    "The perceptron decision boundary is fundamentally a straight line (in the original or warped space), and:\n",
    "- XOR needs at least **two** lines\n",
    "- Circles need a **curved** (circular) boundary\n",
    "\n",
    "Even though activation functions warp space, a **single perceptron** can only create one linear decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_perceptron_limits(dataset_name, w1, w2, b, activation_name):\n",
    "    \"\"\"\n",
    "    Test perceptron on challenging datasets.\n",
    "    \"\"\"\n",
    "    # Select dataset\n",
    "    if dataset_name == \"XOR\":\n",
    "        X, y_true = X_xor, y_xor\n",
    "        title = \"XOR Pattern\"\n",
    "    else:\n",
    "        X, y_true = X_circles, y_circles\n",
    "        title = \"Concentric Circles\"\n",
    "    \n",
    "    # Select activation\n",
    "    activations = {\n",
    "        'Sigmoid': sigmoid,\n",
    "        'Tanh': tanh,\n",
    "        'ReLU': relu,\n",
    "        'Step': step\n",
    "    }\n",
    "    activation = activations[activation_name]\n",
    "    \n",
    "    # Create grid for decision boundary visualization\n",
    "    x1_grid = np.linspace(-3, 3, 200)\n",
    "    x2_grid = np.linspace(-3, 3, 200)\n",
    "    X1_grid, X2_grid = np.meshgrid(x1_grid, x2_grid)\n",
    "    grid_points = np.column_stack([X1_grid.ravel(), X2_grid.ravel()])\n",
    "    \n",
    "    # Compute predictions\n",
    "    z_grid = w1 * grid_points[:, 0] + w2 * grid_points[:, 1] + b\n",
    "    output_grid = activation(z_grid)\n",
    "    \n",
    "    # Threshold\n",
    "    if activation_name in ['Sigmoid', 'Tanh']:\n",
    "        threshold = 0.5 if activation_name == 'Sigmoid' else 0.0\n",
    "    else:\n",
    "        threshold = 0.5\n",
    "    \n",
    "    predictions_grid = (output_grid > threshold).astype(int).reshape(X1_grid.shape)\n",
    "    \n",
    "    # Classify data points\n",
    "    z_data = w1 * X[:, 0] + w2 * X[:, 1] + b\n",
    "    output_data = activation(z_data)\n",
    "    predictions_data = (output_data > threshold).astype(int)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    accuracy = np.mean(predictions_data == y_true) * 100\n",
    "    \n",
    "    # Identify misclassified points\n",
    "    correct = predictions_data == y_true\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 10), dpi=100)\n",
    "    \n",
    "    # Plot decision regions\n",
    "    ax.contourf(X1_grid, X2_grid, predictions_grid, \n",
    "               levels=[-0.5, 0.5, 1.5], colors=['lightblue', 'lightcoral'], alpha=0.3)\n",
    "    \n",
    "    # Plot decision boundary\n",
    "    ax.contour(X1_grid, X2_grid, predictions_grid, \n",
    "              levels=[0.5], colors=['green'], linewidths=3, linestyles='solid')\n",
    "    \n",
    "    # Plot correctly classified points\n",
    "    ax.scatter(X[correct & (y_true == 0), 0], X[correct & (y_true == 0), 1],\n",
    "              c='blue', s=100, alpha=0.7, edgecolors='black', linewidths=1.5, label='Class 0 (correct)')\n",
    "    ax.scatter(X[correct & (y_true == 1), 0], X[correct & (y_true == 1), 1],\n",
    "              c='red', s=100, alpha=0.7, edgecolors='black', linewidths=1.5, label='Class 1 (correct)')\n",
    "    \n",
    "    # Plot misclassified points\n",
    "    if not correct.all():\n",
    "        ax.scatter(X[~correct, 0], X[~correct, 1],\n",
    "                  c='yellow', s=150, alpha=0.9, edgecolors='red', linewidths=4, \n",
    "                  label='Misclassified', marker='X')\n",
    "    \n",
    "    ax.set_xlabel('xâ‚', fontsize=13)\n",
    "    ax.set_ylabel('xâ‚‚', fontsize=13)\n",
    "    ax.set_title(f'{title} | {activation_name} Activation\\nAccuracy: {accuracy:.1f}%', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.legend(fontsize=10, loc='upper left')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim(-3, 3)\n",
    "    ax.set_ylim(-3, 3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analysis\n",
    "    print(f\"\\nDataset: {title}\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"  Weighted sum: z = {w1:.2f}Ã—xâ‚ + {w2:.2f}Ã—xâ‚‚ + {b:.2f}\")\n",
    "    print(f\"  Activation: {activation_name}(z)\")\n",
    "    print(f\"  Accuracy: {accuracy:.1f}% ({int(accuracy * len(y_true) / 100)}/{len(y_true)} correct)\")\n",
    "    \n",
    "    if accuracy > 75:\n",
    "        print(\"\\nğŸ¤” Interesting! You found a configuration that does better than random.\")\n",
    "        print(\"   But notice: You still can't get close to 100%.\")\n",
    "    elif accuracy > 55:\n",
    "        print(\"\\nğŸ’¡ You're slightly better than random guessing (50%).\")\n",
    "        print(\"   But a single straight line can never fully separate this pattern.\")\n",
    "    elif accuracy > 45:\n",
    "        print(\"\\nğŸ˜• This is about the same as random guessing (50%).\")\n",
    "        print(\"   No matter how you adjust the parameters, you can't get much better!\")\n",
    "    else:\n",
    "        print(\"\\nğŸ”„ You're actually doing worse than random! Try flipping some parameters.\")\n",
    "    \n",
    "    # Explain the limitation\n",
    "    print(\"\\nğŸ”‘ Key Insight:\")\n",
    "    if dataset_name == \"XOR\":\n",
    "        print(\"   The perceptron creates ONE straight boundary.\")\n",
    "        print(\"   But XOR needs TWO boundaries (or one curved boundary).\")\n",
    "        print(\"   â†’ A single perceptron CANNOT solve XOR!\")\n",
    "    else:\n",
    "        print(\"   The perceptron creates ONE straight boundary.\")\n",
    "        print(\"   But circles need a CIRCULAR boundary.\")\n",
    "        print(\"   â†’ A single perceptron CANNOT solve concentric circles!\")\n",
    "\n",
    "# Interactive widget\n",
    "print(\"Test Perceptron on Impossible Problems\")\n",
    "print(\"=\"*70)\n",
    "print(\"Try different parameters and activations. Can you solve these patterns?\\n\")\n",
    "\n",
    "interact(\n",
    "    test_perceptron_limits,\n",
    "    dataset_name=Dropdown(\n",
    "        options=['XOR', 'Circles'],\n",
    "        value='XOR',\n",
    "        description='Dataset:'\n",
    "    ),\n",
    "    w1=FloatSlider(min=-3, max=3, step=0.1, value=1.0, description='Weight wâ‚:', continuous_update=False),\n",
    "    w2=FloatSlider(min=-3, max=3, step=0.1, value=1.0, description='Weight wâ‚‚:', continuous_update=False),\n",
    "    b=FloatSlider(min=-5, max=5, step=0.1, value=0.0, description='Bias b:', continuous_update=False),\n",
    "    activation_name=Dropdown(\n",
    "        options=['Sigmoid', 'Tanh', 'ReLU', 'Step'],\n",
    "        value='Sigmoid',\n",
    "        description='Activation:'\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Why Does the Perceptron Fail?\n",
    "\n",
    "Let's understand the fundamental limitation.\n",
    "\n",
    "### What a Perceptron Can Do:\n",
    "1. **Weighted sum:** `z = wâ‚Ã—xâ‚ + wâ‚‚Ã—xâ‚‚ + b` â†’ This defines a **line** in 2D space\n",
    "2. **Activation:** Applies a function to `z`, but keeps the decision boundary as a line\n",
    "3. **Result:** ONE straight boundary (even after activation warping!)\n",
    "\n",
    "### Why This Fails:\n",
    "\n",
    "**For XOR:**\n",
    "- Bottom-left and top-right corners are Class 0\n",
    "- Top-left and bottom-right corners are Class 1\n",
    "- You need **at least 2 lines** to separate these 4 regions\n",
    "- ONE line can separate at most 2 regions, not 4\n",
    "\n",
    "**For Circles:**\n",
    "- Inner points are Class 0\n",
    "- Outer points are Class 1\n",
    "- You need a **circular** boundary\n",
    "- A straight line will always have both classes on both sides\n",
    "\n",
    "### The Critical Realization:\n",
    "Even though activation functions **warp space**, a single perceptron still creates only **one decision boundary**.\n",
    "\n",
    "To solve XOR or circles, you need:\n",
    "- **Multiple perceptrons** working together\n",
    "- **Layered architecture** (hidden layers)\n",
    "- **Combinations** of decision boundaries\n",
    "\n",
    "â†’ That's why neural networks have **multiple layers**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The Solution: Multi-Layer Networks\n",
    "\n",
    "### Single Perceptron (what you just tried):\n",
    "```\n",
    "Input layer          Perceptron            Output\n",
    "    xâ‚  â”€â”€â”€â”€â”\n",
    "            â”œâ”€â”€â”€â†’ [z = wâ‚xâ‚ + wâ‚‚xâ‚‚ + b] â”€â”€â†’ [Ïƒ(z)] â”€â”€â†’ output\n",
    "    xâ‚‚  â”€â”€â”€â”€â”˜\n",
    "            \n",
    "Result: ONE decision boundary â†’ Can't solve XOR or circles\n",
    "```\n",
    "\n",
    "### Multi-Layer Network (the solution):\n",
    "```\n",
    "Input layer    Hidden layer           Output layer\n",
    "    xâ‚  â”€â”€â”€â”€â”\n",
    "            â”œâ”€â”€â†’ [perceptron 1]â”€â”€â”\n",
    "    xâ‚‚  â”€â”€â”€â”€â”¤                    â”‚\n",
    "            â”œâ”€â”€â†’ [perceptron 2]â”€â”€â”¼â”€â”€â†’ [final perceptron] â”€â”€â†’ output\n",
    "            â”‚                    â”‚\n",
    "            â””â”€â”€â†’ [perceptron 3]â”€â”€â”˜\n",
    "            \n",
    "Result: MULTIPLE decision boundaries combined â†’ Can solve XOR and circles!\n",
    "```\n",
    "\n",
    "### How It Works:\n",
    "1. **Hidden layer perceptrons** each create one decision boundary\n",
    "2. **Output perceptron** combines these boundaries\n",
    "3. **Result:** Complex, nonlinear decision regions!\n",
    "\n",
    "**Example for XOR:**\n",
    "- Perceptron 1: Separates left from right\n",
    "- Perceptron 2: Separates top from bottom\n",
    "- Output perceptron: Combines these to identify the diagonal pattern\n",
    "\n",
    "**This is the essence of deep learning:** Simple units (perceptrons) combined in layers create powerful models that can learn any pattern!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary: What You've Learned\n",
    "\n",
    "### Single Perceptron:\n",
    "âœ… **Can solve:** Linearly separable problems (Datasets 1-5 from Module 3)\n",
    "âŒ **Cannot solve:** XOR, circles, or any non-linearly separable pattern\n",
    "\n",
    "### Why?\n",
    "- A perceptron creates **one linear decision boundary**\n",
    "- Activation functions warp space, but don't add more boundaries\n",
    "- Some patterns require multiple or curved boundaries\n",
    "\n",
    "### The Solution:\n",
    "- **Multi-layer neural networks** combine many perceptrons\n",
    "- Hidden layers create multiple decision boundaries\n",
    "- Output layer combines these boundaries\n",
    "- Result: Can learn arbitrarily complex patterns!\n",
    "\n",
    "### Historical Note:\n",
    "This limitation of single-layer perceptrons was famously proven by Minsky & Papert in 1969. It caused the first \"AI winter\" because people thought neural networks were fundamentally limited. \n",
    "\n",
    "The solution (multi-layer networks with backpropagation) was developed in the 1980s, leading to the neural network revolution we're experiencing today!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions for Your Answer Sheet\n",
    "\n",
    "**Q23.** What was the best accuracy you could achieve on the XOR pattern? Was it close to 100%?\n",
    "\n",
    "**Q24.** What was the best accuracy you could achieve on the concentric circles? Was it close to 100%?\n",
    "\n",
    "**Q25.** For the XOR pattern, no matter how you adjust wâ‚, wâ‚‚, and b, why can't a single straight line (the perceptron's decision boundary) separate all four clusters correctly?\n",
    "\n",
    "**Q26.** For the concentric circles, explain why a straight line will always have both blue and red points on both sides of it.\n",
    "\n",
    "**Q27.** In Section 5, we saw that multi-layer networks can solve XOR and circles by combining multiple decision boundaries. How many perceptrons in the hidden layer do you think would be needed to solve XOR? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Answer Q23-Q27** on your answer sheet\n",
    "2. **Return to the LMS** to submit your completed answer sheet\n",
    "3. **Congratulations!** You've completed Lab 3 and understand:\n",
    "   - Why linear models fail on some patterns\n",
    "   - How activation functions warp space\n",
    "   - How perceptrons work (weighted sum â†’ activation)\n",
    "   - Why single perceptrons have limits\n",
    "   - Why neural networks need multiple layers\n",
    "\n",
    "You're now ready to learn about deep neural networks in future labs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
