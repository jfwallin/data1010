{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8, Module 0: What Is a Diffusion Model?\n",
    "\n",
    "**Estimated time:** 5-8 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## **Opening: From Analysis to Synthesis**\n",
    "\n",
    "In Lab 7, you learned how CNNs **analyze** images‚Äîtaking a photo and answering \"What is this?\"\n",
    "\n",
    "But what if we want to go the other direction? What if we want to **create** images from scratch?\n",
    "\n",
    "This is the challenge of **generative AI**:\n",
    "- DALL-E creates images from text descriptions\n",
    "- Midjourney turns words into artwork\n",
    "- Stable Diffusion generates photos that look real\n",
    "\n",
    "**How do these systems work?**\n",
    "\n",
    "The answer is **diffusion models**‚Äîa clever technique that learns to reverse the process of adding noise to images.\n",
    "\n",
    "In this lab, you'll understand how AI systems generate images from pure randomness, train your own mini diffusion model, and see the same principles that power DALL-E in action.\n",
    "\n",
    "---\n",
    "\n",
    "## üìò **What Is a Diffusion Model? (The Big Idea)**\n",
    "\n",
    "**Diffusion models work in two phases:**\n",
    "\n",
    "> **Phase 1 (Forward Diffusion):** Gradually add noise to an image until it becomes pure random noise\n",
    ">\n",
    "> **Phase 2 (Reverse Diffusion):** Train a neural network to reverse this process‚Äîremoving noise step by step to recover (or create) images\n",
    "\n",
    "**In plain language:**\n",
    "1. Take a clean image (like a photo of a cat)\n",
    "2. Add a little bit of noise ‚Üí slightly blurry cat\n",
    "3. Add more noise ‚Üí very blurry cat\n",
    "4. Keep adding noise ‚Üí unrecognizable blur\n",
    "5. Eventually ‚Üí pure random static (no cat visible)\n",
    "\n",
    "**Now train a model to reverse each step:**\n",
    "- Given a noisy image, predict what noise was added\n",
    "- Remove that predicted noise\n",
    "- Repeat many times: noise ‚Üí blur ‚Üí cat!\n",
    "\n",
    "**The magic:** Once trained, you can start from **pure noise** and the model will gradually \"denoise\" it into a realistic image!\n",
    "\n",
    "---\n",
    "\n",
    "## üé® **Analogy: Sculpting in Reverse**\n",
    "\n",
    "Imagine a sculptor working with marble:\n",
    "\n",
    "**Normal sculpting (destructive process):**\n",
    "- Start with a block of marble\n",
    "- Chip away pieces\n",
    "- Gradually reveal a statue\n",
    "- Can't undo‚Äîeach chip is permanent\n",
    "\n",
    "**Reverse sculpting (diffusion):**\n",
    "- Start with marble dust (chaos)\n",
    "- Reassemble tiny pieces\n",
    "- Gradually build structure\n",
    "- End with a coherent statue\n",
    "\n",
    "**Diffusion models do the \"impossible\":**\n",
    "- Forward process: Image ‚Üí Dust (easy, just add randomness)\n",
    "- Reverse process: Dust ‚Üí Image (hard! Need to learn structure)\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ **The Two-Phase Process**\n",
    "\n",
    "### **Phase 1: Forward Diffusion (Destroy)**\n",
    "\n",
    "This is the **easy** part‚Äîjust add noise!\n",
    "\n",
    "```\n",
    "t=0   Clean image        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
    "t=50  Slightly noisy     ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì\n",
    "t=100 Very noisy         ‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí\n",
    "t=150 Barely visible     ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\n",
    "t=200 Pure noise         ......\n",
    "```\n",
    "\n",
    "**Mathematical formulation:**\n",
    "```\n",
    "noisy_image = ‚àö(signal_weight) √ó original + ‚àö(noise_weight) √ó random_noise\n",
    "```\n",
    "\n",
    "As time `t` increases:\n",
    "- `signal_weight` decreases (less original image)\n",
    "- `noise_weight` increases (more random noise)\n",
    "- Eventually, signal disappears completely\n",
    "\n",
    "**Key insight:** This process is **deterministic**‚Äîgiven an image and timestep `t`, we always get the same noisy result.\n",
    "\n",
    "---\n",
    "\n",
    "### **Phase 2: Reverse Diffusion (Create)**\n",
    "\n",
    "This is the **hard** part‚Äîlearn to remove noise!\n",
    "\n",
    "```\n",
    "t=200 Start with noise   ......\n",
    "t=150 Denoise step 1     ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\n",
    "t=100 Denoise step 2     ‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí\n",
    "t=50  Denoise step 3     ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì\n",
    "t=0   Clean image!       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
    "```\n",
    "\n",
    "**What the model learns:**\n",
    "- Input: Noisy image + timestep `t`\n",
    "- Output: Predicted noise that was added\n",
    "- Training: Compare predicted noise to actual noise, adjust weights\n",
    "\n",
    "**Key insight:** The model doesn't directly predict the final image‚Äîit predicts the **noise**, then we subtract it!\n",
    "\n",
    "**Why this works:**\n",
    "- Predicting the full image is too hard (too many pixels, too complex)\n",
    "- Predicting noise is easier (more structured learning signal)\n",
    "- Many small steps are easier than one giant leap\n",
    "\n",
    "---\n",
    "\n",
    "## üî¨ **More Analogies to Build Intuition**\n",
    "\n",
    "### **1. Scrambled Eggs**\n",
    "- **Forward:** Scrambling eggs is easy (add chaos)\n",
    "- **Reverse:** Un-scrambling eggs seems impossible\n",
    "- **Diffusion:** But if you learn the scrambling pattern, you can reverse it step by step!\n",
    "\n",
    "### **2. Photograph in Fog**\n",
    "- **Forward:** Fog gradually covers a photo\n",
    "- **Reverse:** Fog lifts gradually, revealing the photo\n",
    "- **Diffusion:** Model learns to \"lift the fog\" one layer at a time\n",
    "\n",
    "### **3. Detective Work**\n",
    "- **Forward:** Crime scene gets contaminated over time (noise added)\n",
    "- **Reverse:** Detective removes contamination to find original evidence\n",
    "- **Diffusion:** Model is the detective, finding clues to remove noise\n",
    "\n",
    "---\n",
    "\n",
    "## üìä **Connection to Lab 7 (CNNs)**\n",
    "\n",
    "Diffusion models and CNNs solve **opposite problems** using **similar tools**:\n",
    "\n",
    "| Aspect | Lab 7 (CNNs) | Lab 8 (Diffusion) |\n",
    "|--------|--------------|-------------------|\n",
    "| **Task** | Classification (analysis) | Generation (synthesis) |\n",
    "| **Question** | \"What is this?\" | \"Create this!\" |\n",
    "| **Input** | Clean image | Noisy image + timestep |\n",
    "| **Output** | Class probabilities (cat, dog, ...) | Predicted noise |\n",
    "| **Architecture** | CNN (encoder) | U-Net (encoder + decoder) |\n",
    "| **Training** | Gradient descent on classification loss | Gradient descent on noise prediction loss |\n",
    "| **Application** | Face recognition, object detection | Image generation, DALL-E, Midjourney |\n",
    "\n",
    "**Shared foundation:**\n",
    "- Both use convolutional layers (Lab 7 concept!)\n",
    "- Both train with gradient descent (Lab 2 concept!)\n",
    "- Both build hierarchical representations (Lab 4 concept!)\n",
    "\n",
    "**Key difference:**\n",
    "- CNNs **compress** images into small representations (analysis)\n",
    "- Diffusion models **expand** noise into structured images (synthesis)\n",
    "\n",
    "---\n",
    "\n",
    "## üåç **Real-World Applications**\n",
    "\n",
    "Diffusion models power many cutting-edge AI systems:\n",
    "\n",
    "### **Text-to-Image Generation:**\n",
    "- **DALL-E 2** (OpenAI): \"A cat riding a skateboard in space\"\n",
    "- **Midjourney**: Artistic image generation from descriptions\n",
    "- **Stable Diffusion**: Open-source text-to-image synthesis\n",
    "\n",
    "### **Image Editing:**\n",
    "- Inpainting: Fill in missing parts of images\n",
    "- Outpainting: Extend images beyond their borders\n",
    "- Style transfer: Change artistic style while preserving content\n",
    "\n",
    "### **Other Applications:**\n",
    "- **Medical imaging:** Generating training data for rare diseases\n",
    "- **Video generation:** Creating video from text\n",
    "- **Audio synthesis:** Generating music and speech (future lab topic!)\n",
    "- **Molecule design:** Creating new drug candidates\n",
    "\n",
    "**Why diffusion models are powerful:**\n",
    "- High-quality outputs (photorealistic images)\n",
    "- Stable training (compared to GANs)\n",
    "- Flexible (can condition on text, sketches, etc.)\n",
    "- Scalable (work well with large models and datasets)\n",
    "\n",
    "---\n",
    "\n",
    "## üß† **What You'll Learn in This Lab**\n",
    "\n",
    "### **Module 0 (this module):** Conceptual foundation\n",
    "- What diffusion models are\n",
    "- Forward vs. reverse processes\n",
    "- Connection to CNNs\n",
    "\n",
    "### **Module 1:** Forward diffusion demo\n",
    "- Add noise to images progressively\n",
    "- Visualize noise schedules\n",
    "- Understand information loss\n",
    "\n",
    "### **Module 2:** Train a toy denoiser\n",
    "- Build a simplified U-Net\n",
    "- Train on MNIST digits (2-3 minutes!)\n",
    "- Learn to predict noise\n",
    "\n",
    "### **Module 3:** Multi-step denoising\n",
    "- Generate images from pure noise\n",
    "- See iterative refinement\n",
    "- Understand sampling process\n",
    "\n",
    "### **Module 4:** Pre-trained diffusion model\n",
    "- Use Hugging Face diffusers\n",
    "- Generate CIFAR-10 images\n",
    "- Bridge to DALL-E/Stable Diffusion\n",
    "\n",
    "---\n",
    "\n",
    "## üìù **Questions (Q1-Q4)**\n",
    "\n",
    "Before moving on, let's check your understanding. Record your answers in the **Answer Sheet**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q1. In your own words, what is forward diffusion? What is reverse diffusion?**\n",
    "\n",
    "*Hint: Think about adding noise vs. removing noise*\n",
    "\n",
    "**Record your answer in the Answer Sheet.**\n",
    "\n",
    "---\n",
    "\n",
    "### **Q2. Why is it useful to train a model to reverse the noise process? How does this help with image generation?**\n",
    "\n",
    "*Hint: If you can remove noise step by step, you can start from pure noise and create an image!*\n",
    "\n",
    "**Record your answer in the Answer Sheet.**\n",
    "\n",
    "---\n",
    "\n",
    "### **Q3. How is diffusion different from the CNNs you learned about in Lab 7? Look at the comparison table above.**\n",
    "\n",
    "*Hint: CNNs analyze (image ‚Üí class), diffusion generates (noise ‚Üí image)*\n",
    "\n",
    "**Record your answer in the Answer Sheet.**\n",
    "\n",
    "---\n",
    "\n",
    "### **Q4. Predict: When you start from pure random noise at t=200, what determines what image gets generated?**\n",
    "\n",
    "*Hint: In this lab you'll generate digits. In DALL-E, you provide text. What's the common theme?*\n",
    "\n",
    "**Record your answer in the Answer Sheet.**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Module 0 Complete!\n",
    "\n",
    "You now understand:\n",
    "- **What diffusion models are** (reverse process of adding noise)\n",
    "- **Why they work** (many small denoising steps)\n",
    "- **How they differ from CNNs** (synthesis vs. analysis)\n",
    "- **What they're used for** (DALL-E, Midjourney, Stable Diffusion)\n",
    "\n",
    "**Key insight:** Diffusion models learn to create structure from chaos by reversing a gradual noise process!\n",
    "\n",
    "**Ready to see it in action?**\n",
    "\n",
    "Move on to **Module 1: Forward Diffusion Demo**, where you'll progressively add noise to an image and see it transform into pure static!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
