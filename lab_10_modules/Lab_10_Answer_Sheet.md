# Lab 10: AI Self-Assessment and the Hallucination Boundary
## Answer Sheet

**Name:** ___________________________________

**Group Code:** _______________

**Date:** _______________

---

## Module 0: Setup and Understanding AI Self-Assessment

### Q1: Prediction About AI Self-Awareness

**Question:** Before testing, do you think AI models can accurately predict when they will make mistakes? Why or why not?

**Your Answer:**

<br><br><br><br><br>

---

### Q2: Confidence vs. Correctness

**Question:** What's the difference between an AI being **confident** (how it sounds) and being **correct** (actually right)?

**Your Answer:**

<br><br><br><br><br>

---

### Q3: Uncertainty as a Signal

**Question:** If an AI says "I might be wrong about this," does that mean it's **more** likely to be wrong? Make a prediction.

**Your Answer:**

<br><br><br><br><br>

---

## Module 1: Collecting AI Self-Predictions

### Q4: Uncertainty Language in Prompt #1

**Question:** Looking at Prompt #1, did the AI express any uncertainty or caveats? Quote specific phrases from the response.

**Your Answer:**

<br><br><br><br><br>

---

### Q5: Refusals and Strong Uncertainty

**Question:** For which prompt(s) did the AI refuse to answer or express strong uncertainty? List the prompt ID numbers and categories.

**Your Answer:**

<br><br><br><br><br>

---

### Q6: Variation in Confidence

**Question:** Did the AI use similar language for all prompts, or did confidence levels vary across different categories? Give specific examples.

**Your Answer:**

<br><br><br><br><br>

---

### Q7: Predicting Overconfidence

**Question:** PREDICTION: Looking at the 8 responses you collected, for which prompts do you think the AI's self-assessment will be accurate? Which ones do you suspect might show overconfidence (confident tone but actually wrong)?

**Your Answer:**

<br><br><br><br><br>

---

## Module 2: Evaluating AI Responses

### Q8: Verification Method for Prompt #1

**Question:** For Prompt #1, was the AI's response actually accurate? How did you verify this? (What sources did you use?)

**Your Answer:**

<br><br><br><br><br>

---

### Q9: Overconfidence Example

**Question:** Identify ONE prompt where the AI was confident but made errors. What prompt was it? What went wrong?

**Your Answer:**

<br><br><br><br><br>

---

### Q10: Uncertainty and Accuracy

**Question:** Identify ONE prompt where the AI expressed uncertainty (caveats or refusal). Was the AI actually accurate or inaccurate on that prompt?

**Your Answer:**

<br><br><br><br><br>

---

### Q11: Hallucination Example

**Question:** Did you find any "hallucinated" informationâ€”specific false details the AI presented as fact? Give a concrete example.

**Your Answer:**

<br><br><br><br><br>

---

### Q12: Category with Most Errors

**Question:** Which category of prompts led to the most errors in your group's data? Why do you think this category is difficult for AI?

**Your Answer:**

<br><br><br><br><br>

---

## Module 3: Analysis and Visualization

### Q13: Calibration Analysis

**Question:** Looking at your confusion matrix heatmap, how well-calibrated was the AI? Did its confidence levels generally match actual accuracy?

**Your Answer:**

<br><br><br><br><br>

---

### Q14: Overconfidence vs. Underconfidence

**Question:** Was the AI more often **overconfident** (confident but wrong) or **underconfident** (cautious but actually correct)? Which pattern was more common in your data?

**Your Answer:**

<br><br><br><br><br>

---

### Q15: Category Analysis

**Question:** Which category had the highest error rate in your group's data? Why do you think AI struggles with this type of prompt?

**Your Answer:**

<br><br><br><br><br>

---

### Q16: Overconfidence Deep Dive

**Question:** Looking at your most "overconfident" prompt (confident but inaccurate), what do you think caused the AI to fail? Be specific.

**Your Answer:**

<br><br><br><br><br>

---

### Q17: Uncertainty and Performance

**Question:** Looking at your data, did expressing uncertainty (caveats) correlate with lower accuracy? Or were cautious responses sometimes accurate?

**Your Answer:**

<br><br><br><br><br>

---

### Q18: Cross-Group Comparison

**Question:** Compare your results with another group (using their summary JSON file). Did you find similar patterns? What was different?

**Your Answer:**

<br><br><br><br><br>

---

## Module 4: Synthesis and Implications

### Q19: AI Failure Patterns

**Question:** Based on your data from Modules 1-3 and the case studies, complete this sentence:

"AI models are most likely to fail when..."

List at least 3 specific conditions or prompt types that led to errors in your testing.

**Your Answer:**

<br><br><br><br><br>

---

### Q20: Verification Strategies

**Question:** You're writing a research paper and used AI to find sources on climate change impacts. The AI provided 5 citations to scientific papers. What specific steps would you take to verify these citations before including them in your paper?

List at least 3 concrete verification steps.

**Your Answer:**

<br><br><br><br><br>

---

### Q21: Design Trade-offs

**Question:** Consider this dilemma:

**Option A:** AI always expresses strong uncertainty and caveats, even when it's very likely to be correct.
- Result: Users lose trust and find AI less helpful

**Option B:** AI sounds confident to be helpful, even when accuracy is uncertain.
- Result: Users may be misled by overconfident errors

Which option is better? Or is there a middle ground? Explain your reasoning.

**Your Answer:**

<br><br><br><br><br>

---

### Q22: Personal AI Use

**Question:** How will this lab change the way you use AI tools (ChatGPT, Claude, Gemini, etc.) in the future?

Describe at least 2 specific changes you'll make to how you:
- Ask questions
- Interpret responses
- Verify information

**Your Answer:**

<br><br><br><br><br>

---

### Q23: Explaining to Others

**Question:** Imagine a friend says: *"I don't understand why AI can't just tell us when it's going to make a mistake. Can't it check its own answers?"*

Using what you learned in this lab, write a 3-4 sentence explanation of why AI cannot reliably predict its own errors. Use evidence from your group's data if possible.

**Your Answer:**

<br><br><br><br><br>

---

## Summary Statistics (from Module 3)

Record your group's key findings here for reference:

**Total prompts tested:** _______________

**Accurate responses:** _______________ / 8 ( _______ %)

**Confident responses:** _______________ / 8

**Overconfident responses:** _______________ ( _______ % of confident)

**Well-calibrated responses:** _______________

**Category with most errors:** _______________

**Overconfidence rate:** _______ %

---

## Reflection

What was the most surprising finding from this lab?

<br><br><br><br>

What is one thing you'll do differently when using AI tools after completing this lab?

<br><br><br><br>

---

**End of Lab 10 Answer Sheet**
