{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6, Module 3: Tabular Saliency via Feature Perturbation\n",
    "\n",
    "**Estimated time:** 10 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## **Opening: From Pixels to Features**\n",
    "\n",
    "So far, you've explored saliency for:\n",
    "- **Text:** Which words matter? (Module 1)\n",
    "- **Images:** Which pixels matter? (Module 2)\n",
    "\n",
    "Now let's explore saliency for **structured/tabular data**‚Äîthe kind you'd find in spreadsheets and databases.\n",
    "\n",
    "### **Today's Question:**\n",
    "\n",
    "> When predicting if a student will pass an exam, which features matter most: **hours studied**, **attendance rate**, **previous GPA**, or... **zip code**?\n",
    "\n",
    "That last one should raise red flags! Saliency can reveal when models rely on **problematic proxies** for outcomes.\n",
    "\n",
    "---\n",
    "\n",
    "# üìò **Tabular Data and Feature Importance**\n",
    "\n",
    "Unlike text (discrete words) and images (continuous pixels), tabular data has:\n",
    "- **Named features** with clear meanings (age, income, GPA)\n",
    "- **Different scales** (years: 18-80, income: $0-$200k)\n",
    "- **Mixed types** (numerical, categorical)\n",
    "\n",
    "### **The Method: Feature Perturbation**\n",
    "\n",
    "The idea is similar to word masking from Module 1:\n",
    "\n",
    "1. **Get baseline prediction**\n",
    "2. **Perturb one feature at a time** (set it to mean value)\n",
    "3. **Measure prediction change**\n",
    "4. **Large change = important feature**\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Student: hours_studied=8, attendance=0.9, GPA=3.5 ‚Üí 90% pass probability\n",
    "\n",
    "Perturb hours_studied ‚Üí 5 (mean):  ‚Üí 60% pass (change: -30%)\n",
    "Perturb attendance ‚Üí 0.7 (mean):   ‚Üí 85% pass (change: -5%)\n",
    "Perturb GPA ‚Üí 3.0 (mean):          ‚Üí 80% pass (change: -10%)\n",
    "```\n",
    "\n",
    "**Importance ranking:** hours_studied (30%) > GPA (10%) > attendance (5%)\n",
    "\n",
    "---\n",
    "\n",
    "## üß± **Building a Student Performance Predictor**\n",
    "\n",
    "We'll create a toy dataset of student exam outcomes with 4 features:\n",
    "- **hours_studied:** How many hours they studied (0-10)\n",
    "- **attendance_rate:** Fraction of classes attended (0-1)\n",
    "- **homework_completion:** Fraction of homework completed (0-1)\n",
    "- **previous_gpa:** GPA from previous semester (2.0-4.0)\n",
    "\n",
    "Target: **passed_exam** (yes/no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and import libraries\n",
    "!pip install scikit-learn pandas matplotlib numpy -q\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"‚úì Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Generate Synthetic Student Data**\n",
    "\n",
    "We'll create 50 students with realistic relationships between features and outcomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of students\n",
    "n_samples = 50\n",
    "\n",
    "# Generate features\n",
    "data = pd.DataFrame({\n",
    "    'hours_studied': np.random.uniform(0, 10, n_samples),\n",
    "    'attendance_rate': np.random.uniform(0.3, 1.0, n_samples),\n",
    "    'homework_completion': np.random.uniform(0.4, 1.0, n_samples),\n",
    "    'previous_gpa': np.random.uniform(2.0, 4.0, n_samples)\n",
    "})\n",
    "\n",
    "# Generate target (pass/fail) based on weighted combination\n",
    "# More hours + higher GPA ‚Üí more likely to pass\n",
    "success_score = (\n",
    "    data['hours_studied'] * 0.4 +\n",
    "    data['previous_gpa'] * 0.3 +\n",
    "    data['attendance_rate'] * 0.2 +\n",
    "    data['homework_completion'] * 0.1 +\n",
    "    np.random.normal(0, 0.5, n_samples)  # Add noise\n",
    ")\n",
    "\n",
    "# Convert to binary outcome\n",
    "data['passed'] = (success_score > 2.5).astype(int)\n",
    "\n",
    "print(f\"Dataset created: {n_samples} students\")\n",
    "print(f\"  Passed: {data['passed'].sum()} ({data['passed'].mean()*100:.1f}%)\")\n",
    "print(f\"  Failed: {(1-data['passed']).sum()} ({(1-data['passed'].mean())*100:.1f}%)\")\n",
    "print(\"\\nFirst 5 students:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Train a Simple Decision Tree**\n",
    "\n",
    "We'll use a decision tree because it's simple and interpretable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "feature_names = ['hours_studied', 'attendance_rate', 'homework_completion', 'previous_gpa']\n",
    "X = data[feature_names]\n",
    "y = data['passed']\n",
    "\n",
    "# Train decision tree\n",
    "model = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Check accuracy\n",
    "train_accuracy = model.score(X, y)\n",
    "print(f\"\\n‚úì Model trained successfully!\")\n",
    "print(f\"Training accuracy: {train_accuracy*100:.1f}%\")\n",
    "print(\"\\nNote: This is on training data only‚Äîthis is a demonstration!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3: Test Predictions on Example Students**\n",
    "\n",
    "Let's see what the model predicts for some test cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create example students\n",
    "examples = pd.DataFrame([\n",
    "    {'hours_studied': 8.0, 'attendance_rate': 0.9, 'homework_completion': 0.95, 'previous_gpa': 3.5,\n",
    "     'description': 'High-performing student'},\n",
    "    {'hours_studied': 2.0, 'attendance_rate': 0.5, 'homework_completion': 0.4, 'previous_gpa': 2.2,\n",
    "     'description': 'Struggling student'},\n",
    "    {'hours_studied': 5.0, 'attendance_rate': 0.75, 'homework_completion': 0.7, 'previous_gpa': 3.0,\n",
    "     'description': 'Average student'}\n",
    "])\n",
    "\n",
    "print(\"Model predictions on example students:\\n\")\n",
    "for idx, row in examples.iterrows():\n",
    "    features = row[feature_names].values.reshape(1, -1)\n",
    "    prob = model.predict_proba(features)[0]\n",
    "    prediction = \"PASS\" if prob[1] > 0.5 else \"FAIL\"\n",
    "    \n",
    "    print(f\"{row['description']}:\")\n",
    "    print(f\"  Hours studied: {row['hours_studied']}, Attendance: {row['attendance_rate']:.2f}, \"\n",
    "          f\"Homework: {row['homework_completion']:.2f}, GPA: {row['previous_gpa']}\")\n",
    "    print(f\"  ‚Üí Prediction: {prediction} ({prob[1]*100:.1f}% probability of passing)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîç **Computing Feature Importance via Perturbation**\n",
    "\n",
    "Now let's see which features matter most for these predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_feature_importance(sample, model, feature_names, reference_data):\n",
    "    \"\"\"\n",
    "    Compute feature importance by perturbing each feature to its mean value.\n",
    "    \n",
    "    Args:\n",
    "        sample: 1D array of feature values\n",
    "        model: Trained sklearn model\n",
    "        feature_names: List of feature names\n",
    "        reference_data: DataFrame with training data (to compute means)\n",
    "    \n",
    "    Returns:\n",
    "        importance_dict: Dictionary mapping feature names to importance scores\n",
    "    \"\"\"\n",
    "    # Get baseline prediction\n",
    "    baseline_prob = model.predict_proba([sample])[0][1]\n",
    "    \n",
    "    importance = {}\n",
    "    \n",
    "    # Perturb each feature\n",
    "    for i, feature in enumerate(feature_names):\n",
    "        # Create perturbed sample\n",
    "        perturbed = sample.copy()\n",
    "        perturbed[i] = reference_data[feature].mean()  # Set to mean\n",
    "        \n",
    "        # Get new prediction\n",
    "        perturbed_prob = model.predict_proba([perturbed])[0][1]\n",
    "        \n",
    "        # Importance = absolute change in probability\n",
    "        importance[feature] = abs(baseline_prob - perturbed_prob)\n",
    "    \n",
    "    return importance, baseline_prob\n",
    "\n",
    "print(\"‚úì Feature importance function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4: Visualize Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_importance(sample_dict, model, feature_names, reference_data, title=\"\"):\n",
    "    \"\"\"\n",
    "    Visualize feature importance as a bar chart.\n",
    "    \"\"\"\n",
    "    sample = np.array([sample_dict[f] for f in feature_names])\n",
    "    importance, baseline_prob = compute_feature_importance(sample, model, feature_names, reference_data)\n",
    "    \n",
    "    # Sort by importance\n",
    "    sorted_features = sorted(importance.items(), key=lambda x: x[1], reverse=True)\n",
    "    features = [f[0] for f in sorted_features]\n",
    "    values = [f[1] for f in sorted_features]\n",
    "    \n",
    "    # Create bar chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(features)))\n",
    "    ax.barh(features, values, color=colors)\n",
    "    ax.set_xlabel('Importance Score (Change in Pass Probability)', fontsize=12)\n",
    "    ax.set_title(f'Feature Importance: {title}\\nBaseline: {baseline_prob*100:.1f}% probability of passing', \n",
    "                 fontsize=12)\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nFeature importance (sorted):\")\n",
    "    for feature, imp in sorted_features:\n",
    "        print(f\"  {feature:25s}: {imp:.3f} (perturbing this changes prediction by {imp*100:.1f}%)\")\n",
    "\n",
    "print(\"‚úì Visualization function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä **Example 1: High-Performing Student**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student1 = {\n",
    "    'hours_studied': 8.0,\n",
    "    'attendance_rate': 0.9,\n",
    "    'homework_completion': 0.95,\n",
    "    'previous_gpa': 3.5\n",
    "}\n",
    "\n",
    "visualize_feature_importance(student1, model, feature_names, X, \"High-Performing Student\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù **Question 15 (Observation)**\n",
    "\n",
    "**Q15.** Which feature had the highest importance for predicting exam success? Does this align with intuition?\n",
    "\n",
    "*Think about: What would you expect to be most predictive of passing an exam?*\n",
    "\n",
    "*Record your answer in the Answer Sheet.*\n",
    "\n",
    "---\n",
    "\n",
    "## üìä **Example 2: Struggling Student**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student2 = {\n",
    "    'hours_studied': 2.0,\n",
    "    'attendance_rate': 0.5,\n",
    "    'homework_completion': 0.4,\n",
    "    'previous_gpa': 2.2\n",
    "}\n",
    "\n",
    "visualize_feature_importance(student2, model, feature_names, X, \"Struggling Student\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **What to Notice:**\n",
    "\n",
    "Feature importance can **vary by student**! For some students, hours studied matters most. For others, GPA or attendance might dominate.\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ **Experimentation: Perturbation Sensitivity**\n",
    "\n",
    "Let's see what happens when we manually perturb features by different amounts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take an average student\n",
    "student_avg = {\n",
    "    'hours_studied': 5.0,\n",
    "    'attendance_rate': 0.75,\n",
    "    'homework_completion': 0.7,\n",
    "    'previous_gpa': 3.0\n",
    "}\n",
    "\n",
    "sample_avg = np.array([student_avg[f] for f in feature_names])\n",
    "baseline = model.predict_proba([sample_avg])[0][1]\n",
    "\n",
    "print(f\"Average student baseline: {baseline*100:.1f}% pass probability\\n\")\n",
    "print(\"Testing perturbations by ¬±1 standard deviation:\\n\")\n",
    "\n",
    "for i, feature in enumerate(feature_names):\n",
    "    std = X[feature].std()\n",
    "    \n",
    "    # Increase by 1 std\n",
    "    perturbed_up = sample_avg.copy()\n",
    "    perturbed_up[i] += std\n",
    "    prob_up = model.predict_proba([perturbed_up])[0][1]\n",
    "    \n",
    "    # Decrease by 1 std\n",
    "    perturbed_down = sample_avg.copy()\n",
    "    perturbed_down[i] -= std\n",
    "    prob_down = model.predict_proba([perturbed_down])[0][1]\n",
    "    \n",
    "    print(f\"{feature:25s}:\")\n",
    "    print(f\"  +1 std ‚Üí {prob_up*100:5.1f}% (change: {(prob_up-baseline)*100:+.1f}%)\")\n",
    "    print(f\"  -1 std ‚Üí {prob_down*100:5.1f}% (change: {(prob_down-baseline)*100:+.1f}%)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù **Question 16 (Experimentation)**\n",
    "\n",
    "**Q16.** Try perturbing different features by ¬±1 standard deviation (see output above). Which perturbation changed the prediction the most?\n",
    "\n",
    "*Record your answer in the Answer Sheet.*\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è **Ethical Issue: Problematic Features**\n",
    "\n",
    "What if we added a **zip code** feature to our model? Let's explore the ethical implications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a zip code feature (simulate socioeconomic proxy)\n",
    "# Let's say zip codes 10001-10050 correlate with higher pass rates\n",
    "data_with_zip = data.copy()\n",
    "data_with_zip['zip_code'] = np.random.choice(range(10001, 10051), n_samples)\n",
    "\n",
    "# Make zip code slightly predictive (problematic!)\n",
    "data_with_zip['zip_code_normalized'] = (data_with_zip['zip_code'] - 10025) / 25\n",
    "\n",
    "# Retrain model with zip code\n",
    "feature_names_biased = feature_names + ['zip_code_normalized']\n",
    "X_biased = data_with_zip[feature_names_biased]\n",
    "y_biased = data_with_zip['passed']\n",
    "\n",
    "model_biased = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "model_biased.fit(X_biased, y_biased)\n",
    "\n",
    "print(\"‚úì Biased model trained (includes zip code feature)\\n\")\n",
    "\n",
    "# Test on student\n",
    "student_test = {\n",
    "    'hours_studied': 5.0,\n",
    "    'attendance_rate': 0.75,\n",
    "    'homework_completion': 0.7,\n",
    "    'previous_gpa': 3.0,\n",
    "    'zip_code_normalized': 0.5  # High-income zip code proxy\n",
    "}\n",
    "\n",
    "visualize_feature_importance(student_test, model_biased, feature_names_biased, X_biased, \n",
    "                             \"Student (with zip code feature)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **What's Wrong Here?**\n",
    "\n",
    "If **zip_code** has high importance, the model is using **geography as a proxy** for success. This could reflect:\n",
    "- Socioeconomic status\n",
    "- School district quality\n",
    "- Historical redlining patterns\n",
    "\n",
    "**This is problematic!** The model might discriminate based on where students live, not their actual ability.\n",
    "\n",
    "---\n",
    "\n",
    "## üìù **Questions 17-18 (Ethics & Application)**\n",
    "\n",
    "**Q17.** If \"zip_code\" had high importance, why might this be problematic for a real education system?\n",
    "\n",
    "*Think about: What does zip code proxy for? Is it fair to judge students by their address? What historical inequities might this reflect?*\n",
    "\n",
    "*Record your answer in the Answer Sheet.*\n",
    "\n",
    "---\n",
    "\n",
    "**Q18.** Name a feature that might be predictive but ethically problematic to use in a real-world model (hiring, lending, admissions).\n",
    "\n",
    "*Examples to consider: Name, gender, age, race, zip code, university name, etc.*\n",
    "\n",
    "*Record your answer in the Answer Sheet.*\n",
    "\n",
    "---\n",
    "\n",
    "## üîó **How Saliency Helps with Fairness Auditing**\n",
    "\n",
    "Feature importance analysis is the **first step** in fairness auditing:\n",
    "\n",
    "1. **Compute saliency** for all features\n",
    "2. **Identify problematic features** (proxies for protected classes)\n",
    "3. **Investigate why** those features are important\n",
    "4. **Remove or mitigate** bias sources\n",
    "5. **Retrain and verify** improvement\n",
    "\n",
    "Real-world tools for this:\n",
    "- **Fairlearn (Microsoft):** Bias detection and mitigation\n",
    "- **AI Fairness 360 (IBM):** Comprehensive fairness toolkit\n",
    "- **What-If Tool (Google):** Interactive model probing\n",
    "- **SHAP:** Advanced feature importance with game theory\n",
    "\n",
    "---\n",
    "\n",
    "## üìù **Question 19 (Reflection - will be in Module 4)**\n",
    "\n",
    "*Note: This question is part of the ethics module.*\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Module 3 Complete!\n",
    "\n",
    "You've learned:\n",
    "- **How to compute feature importance** via perturbation\n",
    "- **Which features drive predictions** in tabular data\n",
    "- **Why some features are ethically problematic** (proxies for protected classes)\n",
    "- **How saliency helps with fairness auditing** (detecting bias)\n",
    "- **The importance of feature selection** in responsible AI\n",
    "\n",
    "**Key Insight:** Saliency isn't just for debugging‚Äîit's crucial for **detecting and preventing discrimination** in automated decision systems.\n",
    "\n",
    "**Next up:** Module 4, where you'll reflect on **ethics and explainability in practice**‚Äîbringing together everything you've learned about responsible AI deployment.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
