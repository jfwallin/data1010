{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10 - Module 4: Synthesis and Implications\n",
    "\n",
    "**Time:** ~10-12 minutes\n",
    "\n",
    "In this final module, you'll synthesize your findings from Modules 1-3 and explore real-world implications.\n",
    "\n",
    "You've discovered:\n",
    "- How often AI's confidence matches its actual accuracy\n",
    "- Which types of prompts lead to overconfidence\n",
    "- Patterns in AI failures across different categories\n",
    "\n",
    "Now you'll learn:\n",
    "- How overconfidence affects real-world AI usage\n",
    "- Strategies for verifying AI-generated information\n",
    "- When to trust AI vs. when to be cautious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Load Your Complete Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "print(\"‚úì Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Drive Setup\n",
    "\n",
    "**IMPORTANT:** This module loads data from your Google Drive (saved in previous modules).\n",
    "\n",
    "Run the cell below to mount Google Drive. You may need to authorize access again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "print(\"Mounting Google Drive...\")\n",
    "drive.mount('/content/drive')\n",
    "LAB_DIR = '/content/drive/MyDrive/DATA1010/Lab10'\n",
    "print(\"Google Drive mounted successfully!\")\n",
    "print(f\"Lab directory: {LAB_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Your Group's Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_code = int(input(\"Enter your group code: \"))\n",
    "\n",
    "# Load complete analysis\n",
    "try:\n",
    "    complete_df = pd.read_csv(f\"{LAB_DIR}/lab10_group_{group_code}_complete.csv\")\n",
    "    \n",
    "    with open(f\"{LAB_DIR}/lab10_group_{group_code}_summary.json\", 'r') as f:\n",
    "        summary = json.load(f)\n",
    "    \n",
    "    print(f\"‚úì Loaded complete analysis for group {group_code}\")\n",
    "    print()\n",
    "    print(\"=\" * 60)\n",
    "    print(\"YOUR GROUP'S KEY FINDINGS (from Module 3)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total prompts tested: {summary['total_prompts']}\")\n",
    "    print(f\"Accurate responses: {summary['accurate_count']}/{summary['total_prompts']} ({summary['accuracy_rate']:.1f}%)\")\n",
    "    print(f\"Confident responses: {summary['confident_count']}/{summary['total_prompts']}\")\n",
    "    print(f\"Overconfident responses: {summary['overconfident_count']} ({summary['overconfidence_rate']:.1f}% of confident)\")\n",
    "    print(f\"Well-calibrated responses: {summary['well_calibrated_count']}\")\n",
    "    print()\n",
    "    print(f\"Category with most errors: {summary['worst_category']} ({summary['worst_category_error_rate']:.1f}% error rate)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå ERROR: Could not find analysis files\")\n",
    "    print(\"Please run Module 3 first to generate the complete analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Consequences of AI Overconfidence\n",
    "\n",
    "The patterns you observed in your data have real-world consequences. Below are four documented cases where AI overconfidence led to serious problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study 1: Legal Brief Hallucinations (2023)\n",
    "\n",
    "**What Happened:**\n",
    "- A lawyer used ChatGPT to research case law for a legal brief\n",
    "- The AI confidently cited 6 court cases with specific case numbers and quotations\n",
    "- All 6 cases were completely fabricated‚Äîthey never existed\n",
    "- The lawyer submitted the brief to federal court without verification\n",
    "\n",
    "**The Outcome:**\n",
    "- The judge discovered the fabricated citations\n",
    "- The lawyer faced sanctions and professional embarrassment\n",
    "- The case became national news\n",
    "\n",
    "**What Went Wrong:**\n",
    "- The AI presented hallucinated citations with **high confidence** (no caveats)\n",
    "- The lawyer trusted the AI without verification\n",
    "- The fabricated citations looked plausible (correct format, realistic details)\n",
    "\n",
    "**Connection to Your Data:**\n",
    "- This is an example of the **\"Citation Request\"** category from your prompts\n",
    "- Did your group find overconfidence in citation-related prompts?\n",
    "- How often did the AI fabricate sources in your tests?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study 2: Medical Misinformation\n",
    "\n",
    "**What Happened:**\n",
    "- A patient used an AI chatbot to research symptoms and treatment options\n",
    "- The AI confidently recommended a specific medication dosage\n",
    "- The dosage was incorrect and potentially dangerous\n",
    "- The AI did not express uncertainty or recommend consulting a doctor\n",
    "\n",
    "**The Outcome:**\n",
    "- The patient followed the AI's advice initially\n",
    "- Fortunately, a pharmacist caught the error before harm occurred\n",
    "- The incident highlighted risks of AI in healthcare contexts\n",
    "\n",
    "**What Went Wrong:**\n",
    "- The AI was overconfident in a domain requiring extreme accuracy\n",
    "- No disclaimers were prominent enough to prevent misuse\n",
    "- The user assumed confidence indicated medical expertise\n",
    "\n",
    "**Connection to Your Data:**\n",
    "- This relates to **\"Factual Recall\"** and **\"Mathematical\"** categories\n",
    "- Did the AI in your tests express uncertainty for health-related or numerical prompts?\n",
    "- Should AI always express strong caveats in medical contexts, even when confident?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study 3: Academic Paper Fabrication\n",
    "\n",
    "**What Happened:**\n",
    "- A student asked an AI to summarize research on a scientific topic\n",
    "- The AI cited 12 academic papers with authors, titles, and journals\n",
    "- The student included these citations in their paper\n",
    "- The professor discovered that 8 of the 12 papers didn't exist\n",
    "\n",
    "**The Outcome:**\n",
    "- The student received a failing grade for academic dishonesty\n",
    "- The student claimed they didn't know AI could fabricate citations\n",
    "- The incident sparked policy discussions about AI use in coursework\n",
    "\n",
    "**What Went Wrong:**\n",
    "- The AI generated plausible-sounding but fake academic references\n",
    "- The student didn't verify sources (assumed AI was accurate)\n",
    "- The fabrications were detailed enough to seem legitimate\n",
    "\n",
    "**Connection to Your Data:**\n",
    "- Another **\"Citation Request\"** failure mode\n",
    "- Did your group's AI hallucinate any sources?\n",
    "- How would you verify academic citations from an AI?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study 4: News Article Fabrication\n",
    "\n",
    "**What Happened:**\n",
    "- A journalist used an AI to check facts about a historical event\n",
    "- The AI confidently provided dates, names, and statistics\n",
    "- Some details were accurate, but several key facts were wrong\n",
    "- The journalist published the article with the errors\n",
    "\n",
    "**The Outcome:**\n",
    "- Readers noticed the factual errors and complained\n",
    "- The publication had to issue a correction\n",
    "- The journalist's credibility was damaged\n",
    "\n",
    "**What Went Wrong:**\n",
    "- The AI mixed accurate and inaccurate information seamlessly\n",
    "- The **partial accuracy** made the errors harder to detect\n",
    "- The confident tone suggested thorough fact-checking had occurred\n",
    "\n",
    "**Connection to Your Data:**\n",
    "- This relates to **\"Factual Recall\"** and **\"Recent Events\"** categories\n",
    "- Did you find cases where AI was \"mostly accurate\" but had critical errors?\n",
    "- How do you detect errors when most of the response is correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to Trust AI: A Framework\n",
    "\n",
    "Based on research and your experimental data, here's a framework for deciding when AI is reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ When AI Is Generally Reliable\n",
    "\n",
    "AI systems tend to be accurate when:\n",
    "\n",
    "1. **Well-established facts with broad agreement**\n",
    "   - Example: \"What is the capital of France?\"\n",
    "   - The answer appears millions of times in training data\n",
    "\n",
    "2. **Simple mathematical calculations**\n",
    "   - Example: \"What is 25% of 80?\"\n",
    "   - Straightforward, verifiable, no ambiguity\n",
    "\n",
    "3. **Commonsense reasoning**\n",
    "   - Example: \"Why do we refrigerate milk?\"\n",
    "   - Basic knowledge with clear, consistent answers\n",
    "\n",
    "4. **General explanations of concepts**\n",
    "   - Example: \"Explain photosynthesis\"\n",
    "   - Well-documented, stable knowledge\n",
    "\n",
    "**But even for these, verification is wise for high-stakes decisions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è When to Use Extra Caution\n",
    "\n",
    "AI systems are prone to errors when:\n",
    "\n",
    "1. **Specific citations or sources are requested**\n",
    "   - AI often fabricates paper titles, authors, or case law\n",
    "   - Always verify citations independently\n",
    "\n",
    "2. **Recent events or current information**\n",
    "   - AI training has a cutoff date (often months or years old)\n",
    "   - Cannot access real-time information\n",
    "\n",
    "3. **Numerical data or statistics**\n",
    "   - AI may confidently state wrong numbers\n",
    "   - Always check statistics against primary sources\n",
    "\n",
    "4. **Ambiguous or underspecified questions**\n",
    "   - AI may guess what you meant and answer the wrong question\n",
    "   - Be specific in your prompts\n",
    "\n",
    "5. **Niche or specialized domains**\n",
    "   - Less training data = higher error rates\n",
    "   - Domain expertise is essential for verification\n",
    "\n",
    "6. **Multi-step reasoning chains**\n",
    "   - AI can make logical errors in complex reasoning\n",
    "   - Check each step of the logic\n",
    "\n",
    "7. **High-stakes decisions** (medical, legal, financial)\n",
    "   - Never rely solely on AI\n",
    "   - Always consult qualified professionals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Verification Strategies\n",
    "\n",
    "How to verify AI-generated information:\n",
    "\n",
    "**For Factual Claims:**\n",
    "1. Search Google for authoritative sources (government sites, academic institutions)\n",
    "2. Check Wikipedia (but verify with additional sources)\n",
    "3. Look for consensus across multiple independent sources\n",
    "4. Prefer primary sources over AI summaries\n",
    "\n",
    "**For Citations:**\n",
    "1. Search for the exact paper/book title in quotes\n",
    "2. Use Google Scholar for academic papers\n",
    "3. Verify authors exist and work in the relevant field\n",
    "4. Check if the journal or publisher is legitimate\n",
    "5. If you can't find it anywhere, assume it's fabricated\n",
    "\n",
    "**For Numerical Data:**\n",
    "1. Find the original data source (government statistics, research papers)\n",
    "2. Recalculate if possible\n",
    "3. Check units and magnitudes for reasonableness\n",
    "\n",
    "**For Reasoning:**\n",
    "1. Work through the logic yourself\n",
    "2. Test the conclusion with simple examples\n",
    "3. Check for common logical fallacies\n",
    "\n",
    "**For Recent Events:**\n",
    "1. Check news sources directly\n",
    "2. Note the AI's training cutoff date\n",
    "3. Be skeptical of specific recent claims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "Answer these questions on your lab handout to synthesize your learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q19: AI Failure Patterns\n",
    "\n",
    "Based on your data from Modules 1-3 and the case studies above, complete this sentence:\n",
    "\n",
    "**\"AI models are most likely to fail when...\"**\n",
    "\n",
    "List at least 3 specific conditions or prompt types that led to errors in your testing.\n",
    "\n",
    "*(Answer on your handout)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q20: Verification Strategies\n",
    "\n",
    "You're writing a research paper and used AI to find sources on climate change impacts.\n",
    "\n",
    "The AI provided 5 citations to scientific papers. What specific steps would you take to verify these citations before including them in your paper?\n",
    "\n",
    "List at least 3 concrete verification steps.\n",
    "\n",
    "*(Answer on your handout)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q21: Design Trade-offs\n",
    "\n",
    "Consider this dilemma:\n",
    "\n",
    "**Option A:** AI always expresses strong uncertainty and caveats, even when it's very likely to be correct.\n",
    "- Result: Users lose trust and find AI less helpful\n",
    "\n",
    "**Option B:** AI sounds confident to be helpful, even when accuracy is uncertain.\n",
    "- Result: Users may be misled by overconfident errors\n",
    "\n",
    "Which option is better? Or is there a middle ground? Explain your reasoning.\n",
    "\n",
    "*(Answer on your handout)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q22: Personal AI Use\n",
    "\n",
    "How will this lab change the way you use AI tools (ChatGPT, Claude, Gemini, etc.) in the future?\n",
    "\n",
    "Describe at least 2 specific changes you'll make to how you:\n",
    "- Ask questions\n",
    "- Interpret responses\n",
    "- Verify information\n",
    "\n",
    "*(Answer on your handout)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q23: Explaining to Others\n",
    "\n",
    "Imagine a friend says: *\"I don't understand why AI can't just tell us when it's going to make a mistake. Can't it check its own answers?\"*\n",
    "\n",
    "Using what you learned in this lab, write a 3-4 sentence explanation of why AI cannot reliably predict its own errors.\n",
    "\n",
    "Use evidence from your group's data if possible.\n",
    "\n",
    "*(Answer on your handout)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Key Takeaways from Lab 10\n",
    "\n",
    "You've completed an investigation into AI self-assessment and discovered several critical insights:\n",
    "\n",
    "### üéØ Core Findings\n",
    "\n",
    "1. **AI Confidence ‚â† AI Accuracy**\n",
    "   - AI can sound very confident while being completely wrong\n",
    "   - Tone and caveats are unreliable indicators of correctness\n",
    "\n",
    "2. **Systematic Weaknesses Exist**\n",
    "   - Citation requests often trigger hallucinations\n",
    "   - Ambiguous questions lead to confident but potentially wrong answers\n",
    "   - Recent events exceed training data boundaries\n",
    "\n",
    "3. **Overconfidence is Common**\n",
    "   - In your data, you likely found cases where AI was confident but wrong\n",
    "   - This pattern appears across different models and contexts\n",
    "\n",
    "4. **AI Cannot Reliably Self-Assess**\n",
    "   - AI cannot consistently predict when it will make mistakes\n",
    "   - Meta-predictions about AI behavior are themselves unreliable\n",
    "\n",
    "### ‚úÖ Practical Guidelines for AI Use\n",
    "\n",
    "**Always Verify When:**\n",
    "- Stakes are high (academic, professional, medical, legal)\n",
    "- Specific sources or citations are provided\n",
    "- Numerical data or statistics are given\n",
    "- Information relates to recent events\n",
    "\n",
    "**Trust But Verify:**\n",
    "- Use multiple independent sources\n",
    "- Check original sources, not summaries\n",
    "- Apply domain knowledge to spot implausible claims\n",
    "\n",
    "**Use AI Effectively:**\n",
    "- Great for brainstorming and initial research\n",
    "- Excellent for explaining concepts\n",
    "- Useful for generating ideas and drafts\n",
    "- **But always verify critical information**\n",
    "\n",
    "### üî¨ Connection to Data Science\n",
    "\n",
    "This lab connects to broader themes in DATA 1010:\n",
    "\n",
    "- **Model Evaluation:** AI systems are evaluated on accuracy, but calibration (confidence matching accuracy) is equally important\n",
    "- **Uncertainty Quantification:** Good models should express appropriate uncertainty\n",
    "- **Human-AI Collaboration:** AI is a tool that requires human judgment and verification\n",
    "- **Responsible AI:** Understanding limitations is essential for ethical deployment\n",
    "\n",
    "### üåç Real-World Impact\n",
    "\n",
    "As AI becomes more prevalent:\n",
    "- Critical thinking and verification skills become more valuable\n",
    "- Understanding AI limitations protects against misinformation\n",
    "- Responsible AI use requires active engagement, not passive acceptance\n",
    "\n",
    "**You now have the tools to use AI effectively and responsibly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! üéâ\n",
    "\n",
    "You've completed Lab 10: AI Self-Assessment and the Hallucination Boundary.\n",
    "\n",
    "### What You've Accomplished:\n",
    "\n",
    "‚úì Generated and tested 8 diverse prompts on a real AI system\n",
    "\n",
    "‚úì Recorded AI confidence levels and made accuracy predictions\n",
    "\n",
    "‚úì Verified actual accuracy through independent research\n",
    "\n",
    "‚úì Visualized patterns of overconfidence in your data\n",
    "\n",
    "‚úì Connected findings to real-world AI failures\n",
    "\n",
    "‚úì Developed strategies for responsible AI use\n",
    "\n",
    "### Final Checklist:\n",
    "\n",
    "- [ ] Completed all questions (Q1-Q23) on your handout\n",
    "- [ ] Saved all CSV files from Modules 1-3\n",
    "- [ ] Reviewed your group's summary statistics\n",
    "- [ ] Compared findings with other groups (if time permits)\n",
    "- [ ] Reflected on how this changes your AI usage\n",
    "\n",
    "### Remember:\n",
    "\n",
    "**AI is a powerful tool, but it requires human judgment, verification, and critical thinking to use effectively.**\n",
    "\n",
    "Thank you for your careful work in this lab!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}