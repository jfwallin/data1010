{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 11 - Module 4: Reflection and Synthesis\n",
    "\n",
    "**Time:** ~10 minutes\n",
    "\n",
    "## Synthesizing Your Findings\n",
    "\n",
    "You've completed the full cycle of human-AI collaboration:\n",
    "1. âœ“ **Generate**: AI created content from your prompt\n",
    "2. âœ“ **Evaluate**: You discovered AI cannot reliably judge its own quality\n",
    "3. âœ“ **Revise**: AI improved when given explicit, rubric-based feedback\n",
    "\n",
    "Now it's time to step back and reflect on what this means for working with AI.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- Synthesize findings from all three stages\n",
    "- Connect lab insights to real-world AI failures\n",
    "- Articulate when AI is a good collaborator vs. when humans must lead\n",
    "- Develop personal principles for responsible AI collaboration\n",
    "\n",
    "### What You'll Do\n",
    "\n",
    "1. Review your findings from Modules 1-3\n",
    "2. Read case studies about AI evaluation failures\n",
    "3. Complete reflection questions\n",
    "4. (Optional) Extension activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "print(\"âœ“ Libraries loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Review Your Original Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt generation system\n",
    "def generate_group_scenario(group_code):\n",
    "    \"\"\"\n",
    "    Generates a deterministic creative prompt based on group code.\n",
    "    8 prompt families Ã— 5-6 variants each = unique scenarios for each group.\n",
    "    \"\"\"\n",
    "    np.random.seed(group_code)\n",
    "    \n",
    "    # 8 Prompt Families\n",
    "    families = [\n",
    "        'Science Explainer',\n",
    "        'Public Service Announcement',\n",
    "        'Museum Exhibit Panel',\n",
    "        'Product Pitch/Campaign',\n",
    "        'Infographic Structure',\n",
    "        'Short Narrative',\n",
    "        'Educational Analogy',\n",
    "        'Debate Position Statement'\n",
    "    ]\n",
    "    \n",
    "    # Select family (deterministic based on group code)\n",
    "    family_idx = group_code % 8\n",
    "    family = families[family_idx]\n",
    "    \n",
    "    # Rubric mapping\n",
    "    rubric_map = {\n",
    "        'Science Explainer': 'General Communication',\n",
    "        'Public Service Announcement': 'Persuasion/Campaign',\n",
    "        'Museum Exhibit Panel': 'General Communication',\n",
    "        'Product Pitch/Campaign': 'Persuasion/Campaign',\n",
    "        'Infographic Structure': 'General Communication',\n",
    "        'Short Narrative': 'Creative/Narrative',\n",
    "        'Educational Analogy': 'General Communication',\n",
    "        'Debate Position Statement': 'Persuasion/Campaign'\n",
    "    }\n",
    "    \n",
    "    # Family-specific prompt generation\n",
    "    if family == 'Science Explainer':\n",
    "        topics = ['quantum entanglement', 'CRISPR gene editing', 'dark matter', \n",
    "                  'neural plasticity', 'photosynthesis']\n",
    "        audiences = ['middle school students', 'first-year college students', 'general public']\n",
    "        tones = ['serious and formal', 'playful and engaging', 'inspiring and aspirational']\n",
    "        \n",
    "        topic = np.random.choice(topics)\n",
    "        audience = np.random.choice(audiences)\n",
    "        tone = np.random.choice(tones)\n",
    "        \n",
    "        prompt = f\"\"\"Write a 300-word explanation of {topic} for {audience}.\n",
    "\n",
    "Requirements:\n",
    "- Use a {tone} tone\n",
    "- Avoid unnecessary jargon\n",
    "- Include at least one concrete example or analogy\n",
    "- Make it engaging and accessible\"\"\"\n",
    "        \n",
    "        variants = {'topic': topic, 'audience': audience, 'tone': tone}\n",
    "    \n",
    "    elif family == 'Public Service Announcement':\n",
    "        issues = ['water conservation', 'mental health awareness', 'digital privacy', \n",
    "                  'food waste reduction', 'voter registration']\n",
    "        audiences = ['young adults (18-25)', 'seniors (65+)', 'parents of young children', 'general public']\n",
    "        constraints = ['include a specific statistic', 'include a clear call to action', \n",
    "                       'address a common misconception']\n",
    "        urgencies = ['moderate', 'high']\n",
    "        \n",
    "        issue = np.random.choice(issues)\n",
    "        audience = np.random.choice(audiences)\n",
    "        constraint = np.random.choice(constraints)\n",
    "        urgency = np.random.choice(urgencies)\n",
    "        \n",
    "        prompt = f\"\"\"Create a Public Service Announcement about {issue} targeting {audience}.\n",
    "\n",
    "Requirements:\n",
    "- Urgency level: {urgency}\n",
    "- Length: 250-350 words\n",
    "- Must {constraint}\n",
    "- Be persuasive but not preachy\"\"\"\n",
    "        \n",
    "        variants = {'issue': issue, 'audience': audience, 'urgency': urgency, 'constraint': constraint}\n",
    "    \n",
    "    elif family == 'Museum Exhibit Panel':\n",
    "        topics = ['Apollo 11 moon landing', 'invention of the printing press', \n",
    "                  'discovery of DNA structure', 'fall of the Berlin Wall', \n",
    "                  'development of the internet']\n",
    "        audience_levels = ['general public', 'high school students', 'history enthusiasts']\n",
    "        tones = ['formal and academic', 'accessible and engaging', 'narrative storytelling']\n",
    "        \n",
    "        topic = np.random.choice(topics)\n",
    "        audience = np.random.choice(audience_levels)\n",
    "        tone = np.random.choice(tones)\n",
    "        \n",
    "        prompt = f\"\"\"Write a museum exhibit panel about the {topic} for {audience}.\n",
    "\n",
    "Requirements:\n",
    "- Length: 300-400 words\n",
    "- Tone: {tone}\n",
    "- Include historical context and significance\n",
    "- Make it informative yet engaging\"\"\"\n",
    "        \n",
    "        variants = {'topic': topic, 'audience': audience, 'tone': tone}\n",
    "    \n",
    "    elif family == 'Product Pitch/Campaign':\n",
    "        products = ['reusable water bottle with built-in filter', 'productivity app for students',\n",
    "                    'sustainable fashion clothing line', 'meal-prep kit service', \n",
    "                    'noise-canceling headphones for remote work']\n",
    "        markets = ['college students', 'busy professionals', 'environmentally conscious consumers', \n",
    "                   'health-focused individuals']\n",
    "        benefits = ['environmental impact', 'cost savings', 'convenience', 'health benefits', 'quality/durability']\n",
    "        tones = ['aspirational and lifestyle-focused', 'practical and problem-solving', \n",
    "                 'humorous and memorable']\n",
    "        \n",
    "        product = np.random.choice(products)\n",
    "        market = np.random.choice(markets)\n",
    "        benefit = np.random.choice(benefits)\n",
    "        tone = np.random.choice(tones)\n",
    "        \n",
    "        prompt = f\"\"\"Create a campaign outline for a {product} targeting {market}.\n",
    "\n",
    "Requirements:\n",
    "- Length: 300-400 words\n",
    "- Primary benefit to emphasize: {benefit}\n",
    "- Tone: {tone}\n",
    "- Include key messaging and target audience insights\"\"\"\n",
    "        \n",
    "        variants = {'product': product, 'market': market, 'benefit': benefit, 'tone': tone}\n",
    "    \n",
    "    elif family == 'Infographic Structure':\n",
    "        topics = ['renewable energy sources comparison', 'stages of sleep and their functions',\n",
    "                  'water cycle explained', 'history of social media platforms', \n",
    "                  'nutrition basics: macro vs micronutrients']\n",
    "        formats = ['timeline', 'comparison chart', 'process flow', 'hierarchical breakdown']\n",
    "        audiences = ['students', 'policymakers', 'general public', 'professionals in the field']\n",
    "        messages = ['emphasize cost-effectiveness', 'highlight environmental impact', \n",
    "                    'focus on practical applications', 'stress health benefits']\n",
    "        \n",
    "        topic = np.random.choice(topics)\n",
    "        format_type = np.random.choice(formats)\n",
    "        audience = np.random.choice(audiences)\n",
    "        message = np.random.choice(messages)\n",
    "        \n",
    "        prompt = f\"\"\"Outline an infographic about {topic} using a {format_type} format for {audience}.\n",
    "\n",
    "Requirements:\n",
    "- Describe the visual structure and organization\n",
    "- Key message to {message}\n",
    "- Length: 250-350 words\n",
    "- Focus on clear, scannable information hierarchy\"\"\"\n",
    "        \n",
    "        variants = {'topic': topic, 'format': format_type, 'audience': audience, 'message': message}\n",
    "    \n",
    "    elif family == 'Short Narrative':\n",
    "        settings = ['space station orbiting Mars', 'lighthouse during a storm', \n",
    "                    'abandoned subway tunnel', 'research lab in Antarctica', \n",
    "                    'small cafÃ© in a foreign city']\n",
    "        tones = ['hopeful and uplifting', 'tense and suspenseful', 'mysterious and contemplative', \n",
    "                 'bittersweet and nostalgic']\n",
    "        constraints = ['include a metaphor about light or darkness', \n",
    "                       'avoid clichÃ©s about fate or destiny',\n",
    "                       'include dialogue that reveals character',\n",
    "                       'use sensory details (sound, smell, texture)']\n",
    "        \n",
    "        setting = np.random.choice(settings)\n",
    "        tone = np.random.choice(tones)\n",
    "        constraint = np.random.choice(constraints)\n",
    "        \n",
    "        prompt = f\"\"\"Write a 400-500 word short story set in a {setting}.\n",
    "\n",
    "Requirements:\n",
    "- Tone: {tone}\n",
    "- Must {constraint}\n",
    "- Create a complete narrative arc (beginning, middle, end)\n",
    "- Show, don't just tell\"\"\"\n",
    "        \n",
    "        variants = {'setting': setting, 'tone': tone, 'constraint': constraint}\n",
    "    \n",
    "    elif family == 'Educational Analogy':\n",
    "        concepts = ['machine learning', 'blockchain technology', 'quantum computing', \n",
    "                    'climate feedback loops', 'compound interest']\n",
    "        analogy_domains = ['cooking', 'sports', 'gardening', 'everyday household objects', \n",
    "                           'transportation systems']\n",
    "        audiences = ['non-technical managers', 'high school students', 'curious beginners', \n",
    "                     'professionals from another field']\n",
    "        \n",
    "        concept = np.random.choice(concepts)\n",
    "        domain = np.random.choice(analogy_domains)\n",
    "        audience = np.random.choice(audiences)\n",
    "        \n",
    "        prompt = f\"\"\"Explain {concept} using an analogy from {domain} for {audience}.\n",
    "\n",
    "Requirements:\n",
    "- Length: 300-400 words\n",
    "- Make the analogy clear and accurate\n",
    "- Explain how the analogy maps to the concept\n",
    "- Avoid oversimplification that loses key insights\"\"\"\n",
    "        \n",
    "        variants = {'concept': concept, 'domain': domain, 'audience': audience}\n",
    "    \n",
    "    else:  # Debate Position Statement\n",
    "        topics = ['universal basic income', 'social media age verification requirements',\n",
    "                  'mandatory voting', 'AI regulation in creative industries', \n",
    "                  'genetic modification of food crops']\n",
    "        positions = ['FOR (supporting)', 'AGAINST (opposing)']\n",
    "        audiences = ['academic/scholarly', 'general public', 'policymakers', 'industry professionals']\n",
    "        \n",
    "        topic = np.random.choice(topics)\n",
    "        position = np.random.choice(positions)\n",
    "        audience = np.random.choice(audiences)\n",
    "        \n",
    "        prompt = f\"\"\"Write a position statement {position} {topic} for an {audience} audience.\n",
    "\n",
    "Requirements:\n",
    "- Length: 350-450 words\n",
    "- Present clear arguments with supporting evidence\n",
    "- Acknowledge and address counterarguments\n",
    "- Maintain logical structure and persuasive tone\"\"\"\n",
    "        \n",
    "        variants = {'topic': topic, 'position': position, 'audience': audience}\n",
    "    \n",
    "    default_rubric = rubric_map[family]\n",
    "    \n",
    "    return {\n",
    "        'group_code': group_code,\n",
    "        'family': family,\n",
    "        'prompt': prompt,\n",
    "        'default_rubric': default_rubric,\n",
    "        'variants': variants\n",
    "    }\n",
    "\n",
    "# Optional: Regenerate scenario if you want to review it\n",
    "regenerate = input(\"Do you want to see your original scenario/prompt again? (yes/no): \")\n",
    "if regenerate.lower() == 'yes':\n",
    "    group_code = int(input(\"Enter your group code: \"))\n",
    "    scenario = generate_group_scenario(group_code)\n",
    "    print(f\"âœ“ Regenerated scenario\")\n",
    "    print(f\"\\nPrompt Family: {scenario['family']}\")\n",
    "    print(f\"Your prompt:\\n{scenario['prompt']}\")\n",
    "else:\n",
    "    print(\"Proceeding with reflection questions...\")\n",
    "\n",
    "print(\"\\nðŸ“‹ Answer all reflection questions (Q18-Q22) on your Lab 11 Answer Sheet.\")\n",
    "print(\"   Refer to your notes from Modules 1-3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Studies: When AI Evaluation Fails\n",
    "\n",
    "The patterns you observed in your lab work reflect real-world challenges. Here are three documented cases where AI's inability to evaluate quality led to problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study 1: Academic Plagiarism Detection Failure\n",
    "\n",
    "**What Happened:**\n",
    "- A university deployed an AI-powered plagiarism detector to flag student essays\n",
    "- The system flagged original student work as \"likely AI-generated\" with high confidence\n",
    "- Students were accused of cheating based on the AI's evaluation\n",
    "- Manual review revealed the AI detector was wrongâ€”the essays were genuinely student-written\n",
    "\n",
    "**The Problem:**\n",
    "- The AI evaluation tool was **overconfident** (gave high probability scores to wrong conclusions)\n",
    "- Humans trusted the AI's judgment without sufficient verification\n",
    "- The system evaluated \"AI-ness\" but couldn't explain **why** specific passages were flagged\n",
    "- Students suffered consequences before human review occurred\n",
    "\n",
    "**Connection to Your Lab:**\n",
    "- Like the AI in your Module 2, this tool couldn't accurately assess quality\n",
    "- Confidence scores didn't correlate with actual accuracy\n",
    "- Human judgment was essential but initially bypassed\n",
    "\n",
    "**Key Lesson:** AI evaluation tools, even those designed specifically for assessment, are unreliable without human oversight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study 2: AI-Generated Peer Review\n",
    "\n",
    "**What Happened:**\n",
    "- Researchers submitted a deliberately **nonsense academic paper** (random jargon, no real content) to test AI review systems\n",
    "- Several AI-powered peer review tools gave the paper **high scores** and recommended acceptance\n",
    "- The AI systems praised the paper's \"clarity,\" \"methodological rigor,\" and \"contributions to the field\"\n",
    "- Human reviewers immediately recognized it as gibberish\n",
    "\n",
    "**The Problem:**\n",
    "- AI couldn't distinguish between **surface features** (academic-sounding language) and **actual quality** (coherent ideas)\n",
    "- The systems evaluated form over substance\n",
    "- High confidence scores gave false credibility to nonsense\n",
    "\n",
    "**Connection to Your Lab:**\n",
    "- Similar to how AI might score itself highly on \"Structure\" while missing that content is vague or wrong\n",
    "- AI focuses on patterns (\"sounds academic\") rather than meaning\n",
    "- Your rubric-based human evaluation caught things AI self-evaluation missed\n",
    "\n",
    "**Key Lesson:** AI can recognize stylistic patterns but often fails at deeper quality assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study 3: Creative Writing Competition Judging\n",
    "\n",
    "**What Happened:**\n",
    "- An online writing contest used AI to evaluate and rank creative short stories\n",
    "- The AI judges consistently gave high scores to stories with:\n",
    "  - Simple vocabulary and sentence structures\n",
    "  - Predictable narrative arcs\n",
    "  - Conventional genre tropes\n",
    "- Original, experimental, or stylistically bold stories scored poorly\n",
    "- Human judges' rankings diverged significantly from AI rankings\n",
    "\n",
    "**The Problem:**\n",
    "- AI penalized **creativity** (what makes writing interesting) while rewarding **conventionality** (what's common in training data)\n",
    "- The system couldn't evaluate subjective aesthetic qualities like \"voice,\" \"emotional impact,\" or \"originality\"\n",
    "- Quantifiable metrics (sentence length, word frequency) don't capture literary quality\n",
    "\n",
    "**Connection to Your Lab:**\n",
    "- If you used the Creative/Narrative rubric, you likely struggled with criteria like \"Engagement\" and \"Creativity\"\n",
    "- AI self-evaluation might miss what makes content **distinctive**\n",
    "- Some qualities require human judgment and taste\n",
    "\n",
    "**Key Lesson:** For subjective, creative domains, AI evaluation is particularly unreliableâ€”human judgment is irreplaceable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When AI Is a Good Collaborator (and When It's Not)\n",
    "\n",
    "Based on your lab experience and these case studies, here's a framework for human-AI collaboration:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… AI Excels At:\n",
    "\n",
    "1. **Generating drafts quickly**\n",
    "   - As you saw in Module 1, AI can produce content fast\n",
    "   - Useful for brainstorming, overcoming writer's block, creating first drafts\n",
    "\n",
    "2. **Revising when given specific feedback**\n",
    "   - Module 3 likely showed improvement when you gave clear, rubric-based guidance\n",
    "   - AI can iterate and adjust based on explicit criteria\n",
    "\n",
    "3. **Following structural constraints**\n",
    "   - Word count, format requirements, stylistic guidelines\n",
    "   - AI is good at \"fill-in-the-blank\" tasks with clear rules\n",
    "\n",
    "4. **Offering alternative phrasings**\n",
    "   - Can suggest different ways to express an idea\n",
    "   - Useful for editing and refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âŒ AI Struggles With:\n",
    "\n",
    "1. **Evaluating its own quality**\n",
    "   - Module 2 likely revealed significant disagreements between your judgment and AI's self-scores\n",
    "   - AI cannot reliably tell when it's done well or poorly\n",
    "\n",
    "2. **Judging subjective qualities**\n",
    "   - Creativity, originality, emotional impact, aesthetic appeal\n",
    "   - These require human taste and context\n",
    "\n",
    "3. **Understanding audience needs deeply**\n",
    "   - AI may guess what an audience wants but lacks genuine empathy or cultural context\n",
    "   - Can miss nuance in \"Audience Fit\"\n",
    "\n",
    "4. **Recognizing when to refuse**\n",
    "   - AI generates even when it shouldn't (factual errors, hallucinations, inappropriate content)\n",
    "   - Lacks judgment about when NOT to produce\n",
    "\n",
    "5. **Maintaining ethical standards**\n",
    "   - Can't reliably evaluate \"Ethics\" criterion without human oversight\n",
    "   - May produce manipulative, misleading, or biased content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ¤ Best Practices for Human-AI Collaboration:\n",
    "\n",
    "1. **Use AI as a first-draft generator, not a final product**\n",
    "   - Start with AI output but assume significant revision needed\n",
    "\n",
    "2. **Apply explicit rubrics and standards**\n",
    "   - As you did in Module 2, define \"good\" clearly before evaluating\n",
    "   - AI works better when criteria are concrete\n",
    "\n",
    "3. **Iterate with human judgment**\n",
    "   - Module 3's cycle: human evaluates â†’ gives specific feedback â†’ AI revises\n",
    "   - Keep human in control of quality standards\n",
    "\n",
    "4. **Never trust AI self-evaluation alone**\n",
    "   - Always verify with independent judgment or external sources\n",
    "   - Especially critical for high-stakes contexts\n",
    "\n",
    "5. **Recognize domain-specific limitations**\n",
    "   - In creative, ethical, or specialized domains, increase human oversight\n",
    "   - AI is a tool, not an expert\n",
    "\n",
    "6. **Document your human contributions**\n",
    "   - In academic or professional work, be transparent about AI use\n",
    "   - Emphasize your evaluation, judgment, and revision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "Answer these on your Lab 11 Answer Sheet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q18: Biggest Disagreement (Review)\n",
    "\n",
    "Looking back at Module 2, where did you **most disagree** with the AI's self-evaluation? Why do you think this disagreement occurred?\n",
    "\n",
    "Was it a case where AI:\n",
    "- Overrated itself (gave higher scores than deserved)?\n",
    "- Underrated itself (gave lower scores than deserved)?\n",
    "- Focused on the wrong aspects of quality?\n",
    "\n",
    "*(Answer on your answer sheet)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q19: AI as a Creative Assistant\n",
    "\n",
    "What did the AI do **well** as a creative assistant in this lab?\n",
    "\n",
    "Consider:\n",
    "- Initial generation in Module 1\n",
    "- Following revision instructions in Module 3\n",
    "- Specific strengths you identified\n",
    "\n",
    "*(Answer on your answer sheet)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q20: What AI Should Never Do Alone\n",
    "\n",
    "Based on your experience, what should AI **never be solely responsible for** in a creative or evaluation workflow?\n",
    "\n",
    "List at least 2-3 tasks where human oversight is essential.\n",
    "\n",
    "*(Answer on your answer sheet)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q21: Teacher Scenario\n",
    "\n",
    "Imagine you're a teacher. A colleague suggests using AI to grade student essays automatically, with AI providing scores and feedback.\n",
    "\n",
    "Would you trust this system? Why or why not?\n",
    "\n",
    "If you would use it, what safeguards or human oversight would you require?\n",
    "\n",
    "If you wouldn't use it, what specific risks concern you most?\n",
    "\n",
    "*(Answer on your answer sheet)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q22: Personal AI Collaboration Principles\n",
    "\n",
    "How will you use AI as a collaborator in the future?\n",
    "\n",
    "Write 3-5 **personal principles** for responsible AI collaboration based on what you learned in this lab.\n",
    "\n",
    "Format: \"I will...\" or \"I will not...\"\n",
    "\n",
    "Examples:\n",
    "- \"I will always verify AI-generated facts before using them in my work\"\n",
    "- \"I will not trust AI self-evaluation without independent judgment\"\n",
    "- \"I will use explicit rubrics when evaluating AI-generated content\"\n",
    "\n",
    "*(Answer on your answer sheet)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Extension Activities\n",
    "\n",
    "If you finish early or want to explore further:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension 1: Cross-Group Rubric Swap\n",
    "\n",
    "**Q23 (Optional):** Swap rubrics with another group. Score your AI's output using **their rubric** instead of yours.\n",
    "\n",
    "Do the scores change significantly?\n",
    "Does a different rubric reveal different strengths/weaknesses?\n",
    "What does this tell you about the importance of **defining evaluation criteria**?\n",
    "\n",
    "*(Answer on your answer sheet if completed)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension 2: Multi-Model Comparison\n",
    "\n",
    "**Q24 (Optional):** Take your original prompt (from Module 0) and run it on a **different AI model**.\n",
    "\n",
    "For example:\n",
    "- If you used ChatGPT, try Claude or Gemini\n",
    "- If you used Claude, try ChatGPT or Gemini\n",
    "\n",
    "Score the new model's output using the same rubric.\n",
    "\n",
    "Compare:\n",
    "- Which model scored higher? On which criteria?\n",
    "- Did different models have different strengths/weaknesses?\n",
    "- Did their self-evaluations differ in accuracy?\n",
    "\n",
    "*(Answer on your answer sheet if completed)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: What You've Accomplished\n",
    "\n",
    "### Complete Lab Journey:\n",
    "\n",
    "âœ… **Module 0:** Generated a unique creative prompt deterministically\n",
    "\n",
    "âœ… **Module 1:** Used AI to generate content; identified initial strengths and weaknesses\n",
    "\n",
    "âœ… **Module 2:** Applied explicit rubrics; discovered AI cannot reliably self-evaluate\n",
    "\n",
    "âœ… **Module 3:** Guided AI revision with rubric feedback; compared improvement systematically\n",
    "\n",
    "âœ… **Module 4:** Synthesized findings; connected to real-world cases; developed collaboration principles\n",
    "\n",
    "### Core Insights:\n",
    "\n",
    "1. **Generation is easier than evaluation**\n",
    "   - AI can produce content quickly\n",
    "   - But assessing quality requires human judgment\n",
    "\n",
    "2. **AI self-evaluation is unreliable**\n",
    "   - Confidence doesn't equal accuracy\n",
    "   - Human-AI disagreement is common and expected\n",
    "\n",
    "3. **Explicit standards improve collaboration**\n",
    "   - Rubrics make \"good\" concrete\n",
    "   - Clear feedback enables better AI revision\n",
    "\n",
    "4. **Humans must maintain oversight**\n",
    "   - AI is a tool, not an authority\n",
    "   - Critical judgment, ethics, and creativity require human involvement\n",
    "\n",
    "### Connections to Previous Labs:\n",
    "\n",
    "**Lab 1-2 (Optimization):**\n",
    "- Evaluation provides the \"error signal\" for improvement\n",
    "- AI can optimize toward a target but needs humans to define what's \"good\"\n",
    "\n",
    "**Lab 4 (Neural Networks):**\n",
    "- Training requires labeled dataâ€”humans must provide ground truth\n",
    "- AI learns from examples but doesn't inherently know quality\n",
    "\n",
    "**Lab 6 (Explainability):**\n",
    "- AI explanations help but don't replace human judgment\n",
    "- Understanding how AI works â‰  trusting it blindly\n",
    "\n",
    "**Lab 10 (Hallucination):**\n",
    "- **Lab 10:** AI can't predict when it will fail (self-assessment)\n",
    "- **Lab 11:** AI can't evaluate when its output is good (self-evaluation)\n",
    "- Both explore limits of AI meta-cognition\n",
    "\n",
    "### Real-World Application:\n",
    "\n",
    "This lab prepares you to:\n",
    "- âœ“ Use AI productively as a creative collaborator\n",
    "- âœ“ Maintain critical oversight and judgment\n",
    "- âœ“ Apply structured evaluation methods (rubrics)\n",
    "- âœ“ Iterate effectively with AI assistance\n",
    "- âœ“ Recognize when AI should and shouldn't be trusted\n",
    "\n",
    "### Final Takeaway:\n",
    "\n",
    "> **AI is an excellent tool for generation and revision when paired with human evaluation and judgment. The future of AI collaboration is not \"AI replaces humans\" but \"humans guide AI toward human-defined standards of quality.\"**\n",
    "\n",
    "---\n",
    "\n",
    "## Congratulations!\n",
    "\n",
    "You've completed Lab 11: Human-AI Collaboration for Creative Problem Solving.\n",
    "\n",
    "You now understand:\n",
    "- When to trust AI\n",
    "- When to maintain human oversight\n",
    "- How to collaborate effectively with AI systems\n",
    "- Why evaluation is harderâ€”and more importantâ€”than generation\n",
    "\n",
    "**Thank you for your thoughtful engagement with this lab!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
