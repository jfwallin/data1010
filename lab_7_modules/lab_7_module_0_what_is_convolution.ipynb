{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7, Module 0: What Is a Convolution?\n",
    "\n",
    "**Estimated time:** 10 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## **Opening: How Computers See Images**\n",
    "\n",
    "When you look at a photo, your brain instantly detects edges, corners, textures, and objects. You recognize a dog by its ears, fur texture, and snout‚Äînot by memorizing every possible pixel arrangement.\n",
    "\n",
    "**How does a computer do the same?**\n",
    "\n",
    "The answer is **convolution**‚Äîa simple but powerful operation that slides small patterns across an image, looking for features like edges, textures, and shapes.\n",
    "\n",
    "In this module, you'll learn the fundamental operation that powers modern computer vision systems, from face recognition on your phone to medical image analysis in hospitals.\n",
    "\n",
    "---\n",
    "\n",
    "## üìò **What Is Convolution? (The Big Idea)**\n",
    "\n",
    "**Convolution is:**\n",
    "> A sliding window operation that detects patterns in an image by multiplying and adding pixel values.\n",
    "\n",
    "**In plain language:**\n",
    "1. You have a small pattern you're looking for (called a **filter** or **kernel**)\n",
    "2. You slide this pattern across the entire image\n",
    "3. At each position, you multiply the filter values with the pixel values\n",
    "4. You add up all those products to get one output number\n",
    "5. That number tells you \"how much the pattern matched\" at that location\n",
    "\n",
    "### **Analogy: Pattern Matching with Stamps**\n",
    "\n",
    "Imagine you have:\n",
    "- A large piece of paper with random marks (the **image**)\n",
    "- A small stamp with a vertical line pattern (the **filter**)\n",
    "\n",
    "You press the stamp at different locations:\n",
    "- Where there's a vertical line, the stamp matches well ‚Üí **high response**\n",
    "- Where there's a horizontal line, the stamp doesn't match ‚Üí **low response**\n",
    "- Where there's nothing, the stamp barely matches ‚Üí **zero response**\n",
    "\n",
    "**That's convolution!** The \"match score\" at each location creates a new image showing where patterns were found.\n",
    "\n",
    "---\n",
    "\n",
    "## üî¢ **The Math (Simple Version)**\n",
    "\n",
    "Don't worry‚Äîwe'll keep this intuitive!\n",
    "\n",
    "### **Basic Formula:**\n",
    "```\n",
    "Convolution = Sliding Window + Multiply-and-Add\n",
    "```\n",
    "\n",
    "### **Example with Tiny Arrays:**\n",
    "\n",
    "**Image patch (3√ó3):**\n",
    "```\n",
    "[1  2  1]\n",
    "[0  1  0]\n",
    "[1  0  1]\n",
    "```\n",
    "\n",
    "**Vertical edge filter (3√ó3):**\n",
    "```\n",
    "[-1  0  1]\n",
    "[-1  0  1]\n",
    "[-1  0  1]\n",
    "```\n",
    "\n",
    "**Convolution operation:**\n",
    "```\n",
    "Output = (1√ó-1) + (2√ó0) + (1√ó1) + \n",
    "         (0√ó-1) + (1√ó0) + (0√ó1) + \n",
    "         (1√ó-1) + (0√ó0) + (1√ó1)\n",
    "       \n",
    "       = -1 + 0 + 1 + 0 + 0 + 0 + -1 + 0 + 1\n",
    "       = 0\n",
    "```\n",
    "\n",
    "**Interpretation:** A result of 0 means this patch doesn't have a strong vertical edge.\n",
    "\n",
    "### **Why This Filter Detects Vertical Edges:**\n",
    "\n",
    "Look at the filter pattern:\n",
    "```\n",
    "[-1  0  1]\n",
    "[-1  0  1]\n",
    "[-1  0  1]\n",
    "```\n",
    "\n",
    "- **Left column:** negative values (dark pixels)\n",
    "- **Middle column:** zeros (ignore)\n",
    "- **Right column:** positive values (bright pixels)\n",
    "\n",
    "**When there's a vertical edge** (dark on left, bright on right), this filter produces a **strong positive response**!\n",
    "\n",
    "---\n",
    "\n",
    "## üîß **Common Filters and What They Detect**\n",
    "\n",
    "Different filters detect different patterns:\n",
    "\n",
    "### **1. Vertical Edge Detector**\n",
    "```\n",
    "[-1  0  1]\n",
    "[-1  0  1]\n",
    "[-1  0  1]\n",
    "```\n",
    "**Detects:** Vertical lines and edges\n",
    "\n",
    "### **2. Horizontal Edge Detector**\n",
    "```\n",
    "[-1 -1 -1]\n",
    "[ 0  0  0]\n",
    "[ 1  1  1]\n",
    "```\n",
    "**Detects:** Horizontal lines and edges\n",
    "\n",
    "### **3. Blur Filter (Averaging)**\n",
    "```\n",
    "[1  1  1]\n",
    "[1  1  1]  √∑ 9\n",
    "[1  1  1]\n",
    "```\n",
    "**Effect:** Averages nearby pixels, smooths noise\n",
    "\n",
    "### **4. Sharpen Filter**\n",
    "```\n",
    "[ 0 -1  0]\n",
    "[-1  5 -1]\n",
    "[ 0 -1  0]\n",
    "```\n",
    "**Effect:** Emphasizes differences, enhances edges\n",
    "\n",
    "### **5. Identity Filter (No Change)**\n",
    "```\n",
    "[0  0  0]\n",
    "[0  1  0]\n",
    "[0  0  0]\n",
    "```\n",
    "**Effect:** Leaves image unchanged (useful for testing!)\n",
    "\n",
    "---\n",
    "\n",
    "## üí° **Why Convolution Works for Images**\n",
    "\n",
    "Convolution is perfect for image processing because of three key properties:\n",
    "\n",
    "### **1. Local Patterns Matter**\n",
    "Nearby pixels are related (they're part of the same edge, texture, or object). Distant pixels are usually unrelated.\n",
    "\n",
    "**Example:** If pixel (10, 15) and pixel (11, 15) are both bright, they're probably part of the same edge. But pixels 100 pixels apart are likely unrelated.\n",
    "\n",
    "### **2. Translation Invariance**\n",
    "The same filter detects the same pattern **anywhere** in the image.\n",
    "\n",
    "**Example:** A vertical edge detector finds vertical edges whether they're:\n",
    "- Top-left corner\n",
    "- Center of the image\n",
    "- Bottom-right corner\n",
    "\n",
    "No need to train separate detectors for each location!\n",
    "\n",
    "### **3. Parameter Sharing**\n",
    "A 3√ó3 filter has only **9 parameters**, but it's applied to the entire image.\n",
    "\n",
    "**Comparison:**\n",
    "- **Fully-connected layer** on 256√ó256 image: ~16 billion parameters\n",
    "- **Convolutional layer** with 32 filters: ~288 parameters\n",
    "\n",
    "**Result:** CNNs are much more efficient than fully-connected networks for images!\n",
    "\n",
    "---\n",
    "\n",
    "## üñºÔ∏è **Hands-On: Tiny Convolution Example**\n",
    "\n",
    "Let's see convolution in action with a simple 5√ó5 image.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Create a simple 5x5 image with a vertical edge\n",
    "image = np.array([\n",
    "    [0, 0, 1, 1, 1],\n",
    "    [0, 0, 1, 1, 1],\n",
    "    [0, 0, 1, 1, 1],\n",
    "    [0, 0, 1, 1, 1],\n",
    "    [0, 0, 1, 1, 1]\n",
    "], dtype=float)\n",
    "\n",
    "# Define three different filters\n",
    "filters = {\n",
    "    'Vertical Edge': np.array([[-1, 0, 1],\n",
    "                               [-1, 0, 1],\n",
    "                               [-1, 0, 1]]),\n",
    "    \n",
    "    'Horizontal Edge': np.array([[-1, -1, -1],\n",
    "                                 [ 0,  0,  0],\n",
    "                                 [ 1,  1,  1]]),\n",
    "    \n",
    "    'Identity': np.array([[0, 0, 0],\n",
    "                         [0, 1, 0],\n",
    "                         [0, 0, 0]])\n",
    "}\n",
    "\n",
    "# Function to perform convolution\n",
    "def convolve2d(image, kernel):\n",
    "    \"\"\"Simple 2D convolution (no padding, stride=1)\"\"\"\n",
    "    i_height, i_width = image.shape\n",
    "    k_height, k_width = kernel.shape\n",
    "    \n",
    "    output_height = i_height - k_height + 1\n",
    "    output_width = i_width - k_width + 1\n",
    "    output = np.zeros((output_height, output_width))\n",
    "    \n",
    "    for i in range(output_height):\n",
    "        for j in range(output_width):\n",
    "            patch = image[i:i+k_height, j:j+k_width]\n",
    "            output[i, j] = np.sum(patch * kernel)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Visualize image and filters\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Plot original image\n",
    "axes[0, 0].imshow(image, cmap='gray', vmin=0, vmax=1)\n",
    "axes[0, 0].set_title('Original Image\\n(5√ó5)', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].grid(True, which='both', color='red', linewidth=0.5)\n",
    "axes[0, 0].set_xticks(np.arange(-0.5, 5, 1))\n",
    "axes[0, 0].set_yticks(np.arange(-0.5, 5, 1))\n",
    "axes[0, 0].set_xticklabels([])\n",
    "axes[0, 0].set_yticklabels([])\n",
    "\n",
    "# Add text to show it has a vertical edge\n",
    "axes[0, 0].text(2.5, -1, 'Notice: Vertical edge at column 2', \n",
    "                ha='center', fontsize=10, style='italic')\n",
    "\n",
    "# Plot each filter and its output\n",
    "for idx, (name, kernel) in enumerate(filters.items()):\n",
    "    # Plot filter\n",
    "    axes[0, idx+1].imshow(kernel, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    axes[0, idx+1].set_title(f'{name} Filter\\n(3√ó3)', fontsize=12, fontweight='bold')\n",
    "    axes[0, idx+1].grid(True, which='both', color='black', linewidth=0.5)\n",
    "    axes[0, idx+1].set_xticks(np.arange(-0.5, 3, 1))\n",
    "    axes[0, idx+1].set_yticks(np.arange(-0.5, 3, 1))\n",
    "    axes[0, idx+1].set_xticklabels([])\n",
    "    axes[0, idx+1].set_yticklabels([])\n",
    "    \n",
    "    # Add filter values as text\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            axes[0, idx+1].text(j, i, f'{kernel[i, j]:.0f}', \n",
    "                               ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Compute and plot output\n",
    "    output = convolve2d(image, kernel)\n",
    "    im = axes[1, idx+1].imshow(output, cmap='RdBu', vmin=-6, vmax=6)\n",
    "    axes[1, idx+1].set_title(f'Output After\\n{name}', fontsize=12, fontweight='bold')\n",
    "    axes[1, idx+1].grid(True, which='both', color='black', linewidth=0.5)\n",
    "    axes[1, idx+1].set_xticks(np.arange(-0.5, 3, 1))\n",
    "    axes[1, idx+1].set_yticks(np.arange(-0.5, 3, 1))\n",
    "    axes[1, idx+1].set_xticklabels([])\n",
    "    axes[1, idx+1].set_yticklabels([])\n",
    "    \n",
    "    # Add output values as text\n",
    "    for i in range(output.shape[0]):\n",
    "        for j in range(output.shape[1]):\n",
    "            axes[1, idx+1].text(j, i, f'{output[i, j]:.1f}', \n",
    "                               ha='center', va='center', fontsize=10)\n",
    "    \n",
    "    # Add colorbar\n",
    "    plt.colorbar(im, ax=axes[1, idx+1], fraction=0.046, pad=0.04)\n",
    "\n",
    "# Hide the bottom-left subplot\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Convolution in Action: How Filters Detect Patterns', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY OBSERVATIONS:\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n1. VERTICAL EDGE FILTER:\")\n",
    "print(\"   - Output shows STRONG positive response (around +6)\")\n",
    "print(\"   - Why? The image has a vertical edge (dark‚Üíbright transition)\")\n",
    "print(\"   - The filter is designed to detect exactly this pattern!\\n\")\n",
    "\n",
    "print(\"2. HORIZONTAL EDGE FILTER:\")\n",
    "print(\"   - Output shows ZERO response (all values near 0)\")\n",
    "print(\"   - Why? The image has no horizontal edges\")\n",
    "print(\"   - The filter is looking for a pattern that doesn't exist here\\n\")\n",
    "\n",
    "print(\"3. IDENTITY FILTER:\")\n",
    "print(\"   - Output looks similar to the original image\")\n",
    "print(\"   - Why? The identity filter preserves the image (multiplies by 1)\")\n",
    "print(\"   - Notice the output is slightly smaller (3√ó3 instead of 5√ó5)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üé® **What Just Happened?**\n",
    "\n",
    "In the visualization above, you saw:\n",
    "\n",
    "1. **Original Image (5√ó5):** A simple pattern with a vertical edge\n",
    "   - Dark pixels (0) on the left\n",
    "   - Bright pixels (1) on the right\n",
    "\n",
    "2. **Three Filters (3√ó3):** Different patterns we're looking for\n",
    "   - Vertical edge detector\n",
    "   - Horizontal edge detector\n",
    "   - Identity filter (no change)\n",
    "\n",
    "3. **Three Outputs (3√ó3):** Results of convolution\n",
    "   - **Vertical edge output:** Strong positive values (filter found the pattern!)\n",
    "   - **Horizontal edge output:** Near zero (pattern not present)\n",
    "   - **Identity output:** Similar to original (filter preserves image)\n",
    "\n",
    "### **Why Did the Output Get Smaller?**\n",
    "\n",
    "Notice the output is 3√ó3, but the input was 5√ó5. Why?\n",
    "\n",
    "**Answer:** The 3√ó3 filter can only fit in certain positions:\n",
    "- Starting at position (0,0), ending at position (2,2)\n",
    "- We get (5-3+1) √ó (5-3+1) = 3√ó3 output positions\n",
    "\n",
    "**In real CNNs:** We often use \"padding\" (adding zeros around the image) to keep the output the same size as the input. We're keeping it simple here!\n",
    "\n",
    "---\n",
    "\n",
    "## üîó **Connection to Lab 4 (Hidden Layers)**\n",
    "\n",
    "Remember Lab 4, Module 0, where you saw how neural networks transform 2D data into higher dimensions?\n",
    "\n",
    "**Convolution does something similar:**\n",
    "\n",
    "| Lab 4 (Fully-Connected) | Lab 7 (Convolution) |\n",
    "|-------------------------|---------------------|\n",
    "| Takes all input values | Takes local patches |\n",
    "| Creates new representation | Creates new representation |\n",
    "| One transformation per neuron | One transformation per filter |\n",
    "| Learns patterns globally | Learns patterns locally |\n",
    "\n",
    "**Both are creating new representations!**\n",
    "- Lab 4: $(x, y) \\rightarrow (h_1, h_2, h_3, \\ldots)$ (hidden layer activations)\n",
    "- Lab 7: Image ‚Üí (edge map, texture map, shape map, ...) (feature maps)\n",
    "\n",
    "**Key difference:**\n",
    "- Fully-connected layers look at the entire input at once\n",
    "- Convolutional layers look at small local patches, one at a time\n",
    "\n",
    "This makes convolution **much more efficient** for images!\n",
    "\n",
    "---\n",
    "\n",
    "## üîó **Connection to Lab 6 (Saliency Maps)**\n",
    "\n",
    "In Lab 6, you learned about **saliency maps**‚Äîvisualizations showing which parts of an input were important for a prediction.\n",
    "\n",
    "**The connection:**\n",
    "- **Lab 6 (Saliency):** Shows **WHERE** the model looks\n",
    "- **Lab 7 (Convolution):** Shows **WHAT** the model extracts\n",
    "\n",
    "**Example: Dog Image Classification**\n",
    "- **Saliency map:** \"The model focused on the dog's face and ears\"\n",
    "- **Convolution feature maps:** \"The model extracted edge patterns, fur textures, and triangular shapes (ears)\"\n",
    "\n",
    "**Together, they explain how CNNs work:**\n",
    "1. Convolution layers extract features (edges, textures, shapes)\n",
    "2. The model uses those features to make predictions\n",
    "3. Saliency maps show which extracted features were most important\n",
    "\n",
    "---\n",
    "\n",
    "## üìù **Questions (Q1-Q4)**\n",
    "\n",
    "Before moving on, let's check your understanding. Record your answers in the **Answer Sheet**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q1. In your own words, what does a convolution operation do?**\n",
    "\n",
    "*Hint: Think about the sliding window + multiply-and-add operation*\n",
    "\n",
    "**Record your answer in the Answer Sheet.**\n",
    "\n",
    "---\n",
    "\n",
    "### **Q2. Look at the vertical edge filter `[[-1,0,1],[-1,0,1],[-1,0,1]]`. Why would this highlight vertical edges?**\n",
    "\n",
    "*Hint: What happens when you multiply this filter with a patch that has dark pixels on the left and bright pixels on the right?*\n",
    "\n",
    "**Record your answer in the Answer Sheet.**\n",
    "\n",
    "---\n",
    "\n",
    "### **Q3. What happens when you convolve an image with the identity filter `[[0,0,0],[0,1,0],[0,0,0]]`?**\n",
    "\n",
    "*Hint: Look at the visualization above. Why does the identity filter preserve the image?*\n",
    "\n",
    "**Record your answer in the Answer Sheet.**\n",
    "\n",
    "---\n",
    "\n",
    "### **Q4. How is convolution different from the dimension-lifting you saw in Lab 4 Module 0? What's similar?**\n",
    "\n",
    "*Hint: Both create new representations. But one looks at the whole input, while the other looks at local patches.*\n",
    "\n",
    "**Record your answer in the Answer Sheet.**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Module 0 Complete!\n",
    "\n",
    "You now understand:\n",
    "- **What convolution is** (sliding window + multiply-and-add)\n",
    "- **Why it works** (local patterns, translation invariance, parameter sharing)\n",
    "- **What filters detect** (edges, textures, patterns)\n",
    "- **How it connects to previous labs** (hidden layers, saliency maps)\n",
    "\n",
    "**Key insight:** Convolution is the fundamental operation that lets computers \"see\" patterns in images!\n",
    "\n",
    "**Ready for real images?**\n",
    "\n",
    "Move on to **Module 1: Applying Filters to Real Images**, where you'll use classic computer vision filters (Sobel, Laplacian, blur, sharpen) on actual photographs!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
