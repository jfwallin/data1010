{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 - Module 0: Lifting Data into Higher Dimensions\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand why adding dimensions can make unsolvable problems solvable\n",
    "- See XOR become separable when lifted to 3D\n",
    "- Connect dimension-lifting to what activation functions and hidden layers do\n",
    "- Build intuition for why neural networks need multiple layers\n",
    "\n",
    "**Time:** ~12-15 minutes\n",
    "\n",
    "---\n",
    "\n",
    "**Remember from Lab 3 - Module 0:** You discovered that XOR cannot be separated by ANY straight line in 2D.\n",
    "\n",
    "**Remember from Lab 3 - Module 4:** A single perceptron (which draws one line) cannot solve XOR, no matter what parameters you use.\n",
    "\n",
    "**Today's Big Idea:** What if we could ADD A NEW DIMENSION that makes the problem solvable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup: Recreate the XOR Problem\n",
    "\n",
    "Let's bring back the XOR pattern from Lab 3 that gave us so much trouble!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport ipywidgets as widgets\nfrom ipywidgets import interact, Dropdown\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Create XOR dataset (4 clusters in corners)\nn_per_corner = 25\ncorners_class0 = [[-1.5, -1.5], [1.5, 1.5]]  # Bottom-left and top-right\ncorners_class1 = [[-1.5, 1.5], [1.5, -1.5]]  # Top-left and bottom-right\n\nX_class0 = []\nX_class1 = []\n\nfor corner in corners_class0:\n    points = np.random.randn(n_per_corner, 2) * 0.3 + corner\n    X_class0.append(points)\n\nfor corner in corners_class1:\n    points = np.random.randn(n_per_corner, 2) * 0.3 + corner\n    X_class1.append(points)\n\nX_class0 = np.vstack(X_class0)\nX_class1 = np.vstack(X_class1)\n\n# Combine into single dataset\nX_2d = np.vstack([X_class0, X_class1])\ny = np.hstack([np.zeros(len(X_class0)), np.ones(len(X_class1))])\n\nprint(\"‚úì XOR dataset created!\")\nprint(f\"  Total points: {len(X_2d)}\")\nprint(f\"  Class 0 (blue): {np.sum(y==0)} points\")\nprint(f\"  Class 1 (red): {np.sum(y==1)} points\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reminder: XOR is Not Separable in 2D\n",
    "\n",
    "Let's visualize the XOR problem again to remind ourselves why it's impossible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot XOR in 2D\n",
    "fig, ax = plt.subplots(figsize=(8, 8), dpi=100)\n",
    "\n",
    "ax.scatter(X_class0[:, 0], X_class0[:, 1], c='blue', s=100, alpha=0.7, \n",
    "          label='Class 0 (Blue)', edgecolors='k', linewidths=1.5)\n",
    "ax.scatter(X_class1[:, 0], X_class1[:, 1], c='red', s=100, alpha=0.7, \n",
    "          label='Class 1 (Red)', edgecolors='k', linewidths=1.5)\n",
    "\n",
    "ax.set_xlabel('x‚ÇÅ', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('x‚ÇÇ', fontsize=14, fontweight='bold')\n",
    "ax.set_title('XOR Pattern in 2D\\n(Impossible to Separate with One Line)', \n",
    "            fontsize=15, fontweight='bold')\n",
    "ax.legend(fontsize=12, loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_aspect('equal')\n",
    "ax.axhline(y=0, color='gray', linewidth=0.5, linestyle='--', alpha=0.5)\n",
    "ax.axvline(x=0, color='gray', linewidth=0.5, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° The Problem:\")\n",
    "print(\"   Blue points are in opposite corners (bottom-left and top-right)\")\n",
    "print(\"   Red points are in opposite corners (top-left and bottom-right)\")\n",
    "print(\"   No single straight line can separate them!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. The Magic Trick: Add a Third Dimension\n\nHere's the key insight: **What if we add a third dimension (x‚ÇÉ) that's computed from x‚ÇÅ and x‚ÇÇ?**\n\nWe'll experiment with several different \"features\" (ways to compute x‚ÇÉ). Each represents a different way to combine the input coordinates:\n\n### Feature Options:\n\n1. **x‚ÇÉ = x‚ÇÅ √ó x‚ÇÇ** (Product) - Captures interaction between coordinates\n2. **x‚ÇÉ = x‚ÇÅ + x‚ÇÇ** (Sum) - Simple addition\n3. **x‚ÇÉ = x‚ÇÅ¬≤ + x‚ÇÇ¬≤** (Sum of squares) - Distance from origin\n4. **x‚ÇÉ = |x‚ÇÅ| + |x‚ÇÇ|** (Manhattan distance) - Absolute values\n5. **x‚ÇÉ = max(x‚ÇÅ, x‚ÇÇ)** (Maximum) - Takes larger coordinate\n\nLet's create all versions and see which ones help separate XOR!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create 3D versions of the data with different features\n\n# Dictionary to store all feature transformations\nfeatures = {}\n\n# Feature 1: Product (x‚ÇÅ √ó x‚ÇÇ)\nfeatures['product'] = {\n    'data': np.column_stack([X_2d, X_2d[:, 0] * X_2d[:, 1]]),\n    'label': 'x‚ÇÉ = x‚ÇÅ √ó x‚ÇÇ',\n    'description': 'Product captures interaction'\n}\n\n# Feature 2: Sum (x‚ÇÅ + x‚ÇÇ)\nfeatures['sum'] = {\n    'data': np.column_stack([X_2d, X_2d[:, 0] + X_2d[:, 1]]),\n    'label': 'x‚ÇÉ = x‚ÇÅ + x‚ÇÇ',\n    'description': 'Simple addition'\n}\n\n# Feature 3: Sum of squares (x‚ÇÅ¬≤ + x‚ÇÇ¬≤)\nfeatures['sum_squares'] = {\n    'data': np.column_stack([X_2d, X_2d[:, 0]**2 + X_2d[:, 1]**2]),\n    'label': 'x‚ÇÉ = x‚ÇÅ¬≤ + x‚ÇÇ¬≤',\n    'description': 'Distance from origin'\n}\n\n# Feature 4: Manhattan distance (|x‚ÇÅ| + |x‚ÇÇ|)\nfeatures['manhattan'] = {\n    'data': np.column_stack([X_2d, np.abs(X_2d[:, 0]) + np.abs(X_2d[:, 1])]),\n    'label': 'x‚ÇÉ = |x‚ÇÅ| + |x‚ÇÇ|',\n    'description': 'Manhattan distance'\n}\n\n# Feature 5: Maximum (max(x‚ÇÅ, x‚ÇÇ))\nfeatures['maximum'] = {\n    'data': np.column_stack([X_2d, np.maximum(X_2d[:, 0], X_2d[:, 1])]),\n    'label': 'x‚ÇÉ = max(x‚ÇÅ, x‚ÇÇ)',\n    'description': 'Maximum coordinate'\n}\n\nprint(\"‚úì Created 5 different 3D feature transformations!\")\nprint(\"\\nOriginal 2D shape:\", X_2d.shape)\nprint(\"New 3D shape:     \", features['product']['data'].shape)\nprint(\"\\nAvailable features:\")\nfor i, (key, feat) in enumerate(features.items(), 1):\n    print(f\"  {i}. {feat['label']:25} - {feat['description']}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Visualize: XOR in 3D Space\n\nNow let's see what happens when we view the XOR data in 3D!\n\n**Instructions:**\n1. Choose a feature from the dropdown menu\n2. **Rotate the plot** by clicking and dragging with your mouse\n3. **Zoom** with scroll wheel or pinch gesture\n4. Look for patterns - can you see if a flat plane could separate blue from red?"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def plot_xor_3d_plotly(feature_type='product'):\n    \"\"\"\n    Plot XOR in 3D using plotly for interactive rotation.\n    \n    Args:\n        feature_type: which feature transformation to use\n    \"\"\"\n    # Get the selected feature data\n    X_3d = features[feature_type]['data']\n    feature_label = features[feature_type]['label']\n    \n    # Create plotly figure\n    fig = go.Figure()\n    \n    # Add Class 0 points (blue)\n    fig.add_trace(go.Scatter3d(\n        x=X_3d[y==0, 0],\n        y=X_3d[y==0, 1],\n        z=X_3d[y==0, 2],\n        mode='markers',\n        name='Class 0 (Blue)',\n        marker=dict(\n            size=8,\n            color='blue',\n            opacity=0.8,\n            line=dict(color='black', width=1)\n        )\n    ))\n    \n    # Add Class 1 points (red)\n    fig.add_trace(go.Scatter3d(\n        x=X_3d[y==1, 0],\n        y=X_3d[y==1, 1],\n        z=X_3d[y==1, 2],\n        mode='markers',\n        name='Class 1 (Red)',\n        marker=dict(\n            size=8,\n            color='red',\n            opacity=0.8,\n            line=dict(color='black', width=1)\n        )\n    ))\n    \n    # Add separating plane (different for each feature)\n    # Create a mesh grid for the plane\n    x_plane = np.linspace(-3, 3, 20)\n    y_plane = np.linspace(-3, 3, 20)\n    X_plane, Y_plane = np.meshgrid(x_plane, y_plane)\n    \n    # Determine the plane equation based on feature\n    if feature_type == 'product':\n        # For x‚ÇÉ = x‚ÇÅ √ó x‚ÇÇ, separating plane is x‚ÇÉ = 0 (horizontal)\n        Z_plane = np.zeros_like(X_plane)\n        plane_color = 'green'\n        plane_name = 'Separating Plane (x‚ÇÉ = 0)'\n    elif feature_type == 'sum':\n        # For x‚ÇÉ = x‚ÇÅ + x‚ÇÇ, separating plane is x‚ÇÉ = 0\n        Z_plane = np.zeros_like(X_plane)\n        plane_color = 'yellow'\n        plane_name = 'Plane (x‚ÇÉ = 0)'\n    elif feature_type == 'sum_squares':\n        # For x‚ÇÉ = x‚ÇÅ¬≤ + x‚ÇÇ¬≤, try plane at mean\n        threshold = np.mean(X_3d[:, 2])\n        Z_plane = np.full_like(X_plane, threshold)\n        plane_color = 'orange'\n        plane_name = f'Plane (x‚ÇÉ = {threshold:.2f})'\n    elif feature_type == 'manhattan':\n        # Similar to sum_squares\n        threshold = np.mean(X_3d[:, 2])\n        Z_plane = np.full_like(X_plane, threshold)\n        plane_color = 'purple'\n        plane_name = f'Plane (x‚ÇÉ = {threshold:.2f})'\n    else:  # maximum\n        threshold = np.mean(X_3d[:, 2])\n        Z_plane = np.full_like(X_plane, threshold)\n        plane_color = 'cyan'\n        plane_name = f'Plane (x‚ÇÉ = {threshold:.2f})'\n    \n    # Add the plane\n    fig.add_trace(go.Surface(\n        x=X_plane,\n        y=Y_plane,\n        z=Z_plane,\n        opacity=0.3,\n        colorscale=[[0, plane_color], [1, plane_color]],\n        showscale=False,\n        name=plane_name,\n        hoverinfo='skip'\n    ))\n    \n    # Update layout\n    fig.update_layout(\n        title=dict(\n            text=f'XOR in 3D Space<br><sub>{feature_label}</sub>',\n            x=0.5,\n            xanchor='center',\n            font=dict(size=16)\n        ),\n        scene=dict(\n            xaxis_title='x‚ÇÅ',\n            yaxis_title='x‚ÇÇ',\n            zaxis_title='x‚ÇÉ',\n            camera=dict(\n                eye=dict(x=1.5, y=1.5, z=1.3)\n            ),\n            aspectmode='cube'\n        ),\n        width=900,\n        height=700,\n        showlegend=True,\n        legend=dict(x=0.7, y=0.9)\n    )\n    \n    # Show the plot\n    fig.show()\n    \n    # Provide feedback based on feature type\n    print(\"\\n\" + \"=\"*70)\n    \n    if feature_type == 'product':\n        # Calculate accuracy\n        pred = (X_3d[:, 2] > 0).astype(int)\n        acc = np.mean(pred == y) * 100\n        \n        print(\"‚úÖ EXCELLENT! With x‚ÇÉ = x‚ÇÅ √ó x‚ÇÇ:\")\n        print(f\"   Accuracy: {acc:.1f}%\")\n        print(\"\\n   üîµ Blue points (Class 0):\")\n        print(\"      ‚Ä¢ Bottom-left: (-)(-)  = + POSITIVE\")\n        print(\"      ‚Ä¢ Top-right:   (+)(+)  = + POSITIVE\")\n        print(\"      ‚Üí Blue points have x‚ÇÉ > 0 (above green plane)\")\n        print(\"\\n   üî¥ Red points (Class 1):\")\n        print(\"      ‚Ä¢ Top-left:     (-)(+)  = - NEGATIVE\")\n        print(\"      ‚Ä¢ Bottom-right: (+)(-)  = - NEGATIVE\")\n        print(\"      ‚Üí Red points have x‚ÇÉ < 0 (below green plane)\")\n        print(\"\\n   üí° The green plane (x‚ÇÉ = 0) perfectly separates them!\")\n        \n    elif feature_type == 'sum':\n        pred = (X_3d[:, 2] > 0).astype(int)\n        acc = np.mean(pred == y) * 100\n        print(f\"‚ö†Ô∏è With x‚ÇÉ = x‚ÇÅ + x‚ÇÇ:\")\n        print(f\"   Accuracy: {acc:.1f}%\")\n        print(\"\\n   This feature doesn't separate XOR well.\")\n        print(\"   Both classes have mixed positive and negative values.\")\n        print(\"   Try switching to 'product' to see perfect separation!\")\n        \n    elif feature_type == 'sum_squares':\n        threshold = np.mean(X_3d[:, 2])\n        pred = (X_3d[:, 2] > threshold).astype(int)\n        acc = np.mean(pred == y) * 100\n        print(f\"‚ö†Ô∏è With x‚ÇÉ = x‚ÇÅ¬≤ + x‚ÇÇ¬≤:\")\n        print(f\"   Accuracy: {acc:.1f}%\")\n        print(\"\\n   This measures distance from origin.\")\n        print(\"   Both classes are at similar distances, so it doesn't help!\")\n        print(\"   All corner points are roughly equidistant from (0,0).\")\n        \n    elif feature_type == 'manhattan':\n        threshold = np.mean(X_3d[:, 2])\n        pred = (X_3d[:, 2] > threshold).astype(int)\n        acc = np.mean(pred == y) * 100\n        print(f\"‚ö†Ô∏è With x‚ÇÉ = |x‚ÇÅ| + |x‚ÇÇ|:\")\n        print(f\"   Accuracy: {acc:.1f}%\")\n        print(\"\\n   Manhattan distance also doesn't help.\")\n        print(\"   All corners are at the same Manhattan distance!\")\n        \n    else:  # maximum\n        threshold = np.mean(X_3d[:, 2])\n        pred = (X_3d[:, 2] > threshold).astype(int)\n        acc = np.mean(pred == y) * 100\n        print(f\"‚ö†Ô∏è With x‚ÇÉ = max(x‚ÇÅ, x‚ÇÇ):\")\n        print(f\"   Accuracy: {acc:.1f}%\")\n        print(\"\\n   Taking the maximum coordinate doesn't separate XOR.\")\n        print(\"   Try 'product' to see the feature that actually works!\")\n    \n    print(\"=\"*70)\n\n# Create interactive widget with dropdown menu\nprint(\"Interactive 3D XOR Visualization\")\nprint(\"=\"*70)\nprint(\"Choose different features to see which one makes XOR separable!\")\nprint(\"Click and drag to rotate | Scroll to zoom | Hover for values\\n\")\n\ninteract(\n    plot_xor_3d_plotly,\n    feature_type=Dropdown(\n        options=[\n            ('Product: x‚ÇÉ = x‚ÇÅ √ó x‚ÇÇ', 'product'),\n            ('Sum: x‚ÇÉ = x‚ÇÅ + x‚ÇÇ', 'sum'),\n            ('Sum of Squares: x‚ÇÉ = x‚ÇÅ¬≤ + x‚ÇÇ¬≤', 'sum_squares'),\n            ('Manhattan: x‚ÇÉ = |x‚ÇÅ| + |x‚ÇÇ|', 'manhattan'),\n            ('Maximum: x‚ÇÉ = max(x‚ÇÅ, x‚ÇÇ)', 'maximum')\n        ],\n        value='product',\n        description='Feature:'\n    )\n);"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. What Just Happened? The Math Behind the Magic\n\nLet's understand WHY the product feature (x‚ÇÉ = x‚ÇÅ √ó x‚ÇÇ) works so well for XOR, while the others fail!\n\n### XOR Pattern in 2D:\n```\nPoint          x‚ÇÅ    x‚ÇÇ    Label\n--------------------------------------\nBottom-left:  -1.5  -1.5   Class 0 (Blue)\nTop-right:    +1.5  +1.5   Class 0 (Blue)\nTop-left:     -1.5  +1.5   Class 1 (Red)\nBottom-right: +1.5  -1.5   Class 1 (Red)\n```\n\n### After Adding Different Features:\n\n**1. Product Feature: x‚ÇÉ = x‚ÇÅ √ó x‚ÇÇ** ‚úÖ *Perfect separation!*\n```\nPoint          x‚ÇÅ    x‚ÇÇ    x‚ÇÉ = x‚ÇÅ√óx‚ÇÇ   Label       Insight\n-------------------------------------------------------------------\nBottom-left:  -1.5  -1.5   +2.25       Class 0     Same sign ‚Üí +\nTop-right:    +1.5  +1.5   +2.25       Class 0     Same sign ‚Üí +\nTop-left:     -1.5  +1.5   -2.25       Class 1     Diff sign ‚Üí -\nBottom-right: +1.5  -1.5   -2.25       Class 1     Diff sign ‚Üí -\n```\n**Rule:** x‚ÇÉ > 0 ‚Üí Class 0 (Blue), x‚ÇÉ < 0 ‚Üí Class 1 (Red) ‚úì Works perfectly!\n\n**2. Sum Feature: x‚ÇÉ = x‚ÇÅ + x‚ÇÇ** ‚ùå *Doesn't help*\n```\nPoint          x‚ÇÅ    x‚ÇÇ    x‚ÇÉ = x‚ÇÅ+x‚ÇÇ   Label\n---------------------------------------------------\nBottom-left:  -1.5  -1.5   -3.0        Class 0\nTop-right:    +1.5  +1.5   +3.0        Class 0\nTop-left:     -1.5  +1.5    0.0        Class 1\nBottom-right: +1.5  -1.5    0.0        Class 1\n```\nClasses overlap in x‚ÇÉ values - no clean separation!\n\n**3. Sum of Squares: x‚ÇÉ = x‚ÇÅ¬≤ + x‚ÇÇ¬≤** ‚ùå *All similar*\n```\nPoint          x‚ÇÅ    x‚ÇÇ    x‚ÇÉ = x‚ÇÅ¬≤+x‚ÇÇ¬≤   Label\n------------------------------------------------------\nBottom-left:  -1.5  -1.5   4.5           Class 0\nTop-right:    +1.5  +1.5   4.5           Class 0\nTop-left:     -1.5  +1.5   4.5           Class 1\nBottom-right: +1.5  -1.5   4.5           Class 1\n```\nAll points equidistant from origin - useless for separation!\n\n### The Key Insight:\n- **Class 0 (Blue):** Both coordinates have the **same sign** ‚Üí product is **POSITIVE**\n- **Class 1 (Red):** Coordinates have **opposite signs** ‚Üí product is **NEGATIVE**\n\nThis captures the **interaction** between x‚ÇÅ and x‚ÇÇ, which is exactly what defines XOR!\n\nNow we can use a simple rule in 3D: **\"If x‚ÇÉ > 0, predict Blue; otherwise predict Red\"**\n\nThis is just a **horizontal plane** at x‚ÇÉ = 0, which is easy for a linear model!"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Project the 3D Plane Back to 2D\n",
    "\n",
    "The really cool part: when you look at the 3D separating plane from above (bird's eye view), what does it look like in 2D?\n",
    "\n",
    "Let's visualize this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show side-by-side: Original 2D problem and what it looks like after lifting\n",
    "fig = plt.figure(figsize=(16, 6), dpi=100)\n",
    "\n",
    "# Left plot: Original 2D XOR (impossible)\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.scatter(X_class0[:, 0], X_class0[:, 1], c='blue', s=100, alpha=0.7,\n",
    "           label='Class 0 (Blue)', edgecolors='k', linewidths=1.5)\n",
    "ax1.scatter(X_class1[:, 0], X_class1[:, 1], c='red', s=100, alpha=0.7,\n",
    "           label='Class 1 (Red)', edgecolors='k', linewidths=1.5)\n",
    "ax1.set_xlabel('x‚ÇÅ', fontsize=13, fontweight='bold')\n",
    "ax1.set_ylabel('x‚ÇÇ', fontsize=13, fontweight='bold')\n",
    "ax1.set_title('BEFORE: XOR in 2D\\n(No straight line works)', \n",
    "             fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_aspect('equal')\n",
    "ax1.axhline(y=0, color='gray', linewidth=0.5, linestyle='--', alpha=0.5)\n",
    "ax1.axvline(x=0, color='gray', linewidth=0.5, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Right plot: Decision boundary based on x‚ÇÉ = x‚ÇÅ √ó x‚ÇÇ\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "# Create a mesh grid\n",
    "x1_range = np.linspace(-3, 3, 200)\n",
    "x2_range = np.linspace(-3, 3, 200)\n",
    "X1_mesh, X2_mesh = np.meshgrid(x1_range, x2_range)\n",
    "\n",
    "# Compute x‚ÇÉ = x‚ÇÅ √ó x‚ÇÇ for each point\n",
    "X3_mesh = X1_mesh * X2_mesh\n",
    "\n",
    "# Decision rule: x‚ÇÉ > 0 ‚Üí Class 0, x‚ÇÉ < 0 ‚Üí Class 1\n",
    "decision = (X3_mesh > 0).astype(int)\n",
    "\n",
    "# Plot decision regions\n",
    "ax2.contourf(X1_mesh, X2_mesh, decision, levels=1, alpha=0.3, colors=['red', 'blue'])\n",
    "\n",
    "# Plot the decision boundary (where x‚ÇÅ √ó x‚ÇÇ = 0)\n",
    "ax2.contour(X1_mesh, X2_mesh, X3_mesh, levels=[0], colors='green', linewidths=3)\n",
    "\n",
    "# Plot data points\n",
    "ax2.scatter(X_class0[:, 0], X_class0[:, 1], c='blue', s=100, alpha=0.7,\n",
    "           label='Class 0 (Blue)', edgecolors='k', linewidths=1.5)\n",
    "ax2.scatter(X_class1[:, 0], X_class1[:, 1], c='red', s=100, alpha=0.7,\n",
    "           label='Class 1 (Red)', edgecolors='k', linewidths=1.5)\n",
    "\n",
    "ax2.set_xlabel('x‚ÇÅ', fontsize=13, fontweight='bold')\n",
    "ax2.set_ylabel('x‚ÇÇ', fontsize=13, fontweight='bold')\n",
    "ax2.set_title('AFTER: Decision Boundary in 2D\\n(Based on x‚ÇÉ = x‚ÇÅ √ó x‚ÇÇ)', \n",
    "             fontsize=13, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_aspect('equal')\n",
    "ax2.set_xlim(-3, 3)\n",
    "ax2.set_ylim(-3, 3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ The Big Reveal:\")\n",
    "print(\"   LEFT: Impossible to separate with a straight line\")\n",
    "print(\"   RIGHT: The 3D plane projects to a CURVED boundary in 2D!\")\n",
    "print(\"\\n   The green curve shows where x‚ÇÅ √ó x‚ÇÇ = 0\")\n",
    "print(\"   (This is a hyperbola - two curves meeting at the origin)\")\n",
    "print(\"\\n   üí° A STRAIGHT PLANE in 3D becomes a CURVED BOUNDARY in 2D!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Connection to Neural Networks\n\n**This is EXACTLY what hidden layers in neural networks do!**\n\n### What You Just Did Manually:\n1. Started with 2D data (x‚ÇÅ, x‚ÇÇ)\n2. **Manually engineered** a new feature: x‚ÇÉ = x‚ÇÅ √ó x‚ÇÇ\n3. Used a simple linear rule in the new 3D space (x‚ÇÉ > 0 ‚Üí Blue)\n4. This gave you a curved boundary in the original 2D space\n\n### What Hidden Layers Do Automatically:\n1. Start with input data (x‚ÇÅ, x‚ÇÇ)\n2. **Automatically learn** new features through hidden neurons\n3. Each hidden neuron creates a new \"dimension\" (like your x‚ÇÉ)\n4. The output layer uses simple linear rules in this new space\n5. Result: Curved boundaries in the original space!\n\n### The Key Insight:\n\n**You don't need to manually figure out which features to add!**\n- Hidden layers **invent useful features automatically** during training\n- They learn which combinations of inputs help separate the classes\n- This is why neural networks are so powerful!\n\n### Remember from Lab 3:\n- **Activation functions** warp space to create curved boundaries\n- But a **single perceptron** still creates only ONE boundary\n\n### Coming in Module 1:\n- **Multiple hidden neurons** create multiple new dimensions\n- Combining these dimensions gives flexible, complex boundaries\n- You'll see a 2-2-1 network solve XOR automatically!"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Key Takeaways from Module 0\n\n### 1. Dimension Lifting Makes Hard Problems Easy\n- XOR is impossible to separate in 2D with a straight line\n- Adding x‚ÇÉ = x‚ÇÅ √ó x‚ÇÇ makes it perfectly separable in 3D\n- A flat plane in 3D becomes a curved boundary in 2D\n- **Not all features help equally!** You discovered which one works best.\n\n### 2. Feature Engineering vs. Feature Learning\n- **Manual (what you did):** You figured out that x‚ÇÉ = x‚ÇÅ √ó x‚ÇÇ helps\n- **Neural Networks:** Hidden layers learn useful features automatically\n- This is why deep learning is powerful - no manual feature design needed!\n- The network discovers the right features during training\n\n### 3. Connection to Hidden Layers\n- Each hidden neuron creates a new \"dimension\" (like the x‚ÇÉ you added)\n- More hidden neurons = more dimensions = more flexibility\n- Output layer makes simple linear decisions in this richer space\n- Complex curved boundaries in original space = simple planes in lifted space\n\n### 4. Why We Need Multiple Layers\n- **Single perceptron:** 1 boundary in original space ‚Üí Can't solve XOR\n- **Hidden layer:** Lifts data to higher dimensions ‚Üí Simple rules work!\n- This is the foundation of all deep learning\n- Next module: See how a 2-2-1 network does this automatically!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Summary\nprint(\"=\"*70)\nprint(\"Next: In Module 1, you'll build a 2-2-1 neural network and see\")\nprint(\"how TWO hidden neurons create two new dimensions to solve XOR!\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions for Your Answer Sheet\n",
    "\n",
    "**Q1.** In 2D, can you draw a straight line that separates the XOR pattern? Why or why not?\n",
    "\n",
    "**Q2.** After adding the third dimension (x‚ÇÉ = x‚ÇÅ √ó x‚ÇÇ), describe what you observed in the 3D plot. Could you see how a flat plane separates the two classes?\n",
    "\n",
    "**Q3.** When you view the 3D separating plane from directly above (bird's eye view), what shape does the decision boundary have in 2D? Is it a straight line?\n",
    "\n",
    "**Q4.** How is adding a third dimension similar to what activation functions did in Lab 3? (Hint: Think about \"transforming\" or \"warping\" space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Answer Q1-Q4** on your answer sheet\n",
    "2. **Return to the LMS** and continue to Module 1\n",
    "3. In Module 1, you'll see how a 2-2-1 neural network solves XOR by creating two new dimensions automatically!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}