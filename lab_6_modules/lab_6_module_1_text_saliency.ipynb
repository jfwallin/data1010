{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6, Module 1: Text Saliency with Word Masking\n",
    "\n",
    "**Estimated time:** 15 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## **Opening: From Embeddings to Decisions**\n",
    "\n",
    "In **Lab 5**, you learned how AI systems represent words as vectorsâ€”embeddings that capture meaning as geometry.\n",
    "\n",
    "But knowing that \"excellent\" and \"terrible\" have different embeddings doesn't tell us **which words drive a model's predictions**.\n",
    "\n",
    "### **Today's Question:**\n",
    "> When a sentiment classifier reads \"The movie was surprisingly excellent but the acting was terrible\", **which words matter most** for determining if the review is positive or negative?\n",
    "\n",
    "In this module, you'll:\n",
    "1. Train a simple sentiment classifier on movie reviews\n",
    "2. Compute **word importance** by masking words one at a time\n",
    "3. Visualize which words drive positive vs. negative predictions\n",
    "4. Experiment with your own sentences\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ“˜ **How Word Masking Works**\n",
    "\n",
    "The core idea is beautifully simple:\n",
    "\n",
    "### **Step 1: Get baseline prediction**\n",
    "```\n",
    "Sentence: \"The movie was excellent\"\n",
    "Model prediction: 95% positive\n",
    "```\n",
    "\n",
    "### **Step 2: Remove one word at a time**\n",
    "```\n",
    "Remove \"The\":        \"movie was excellent\"     â†’ 94% positive (change: -1%)\n",
    "Remove \"movie\":      \"The was excellent\"       â†’ 92% positive (change: -3%)\n",
    "Remove \"was\":        \"The movie excellent\"     â†’ 93% positive (change: -2%)\n",
    "Remove \"excellent\": \"The movie was\"           â†’ 50% positive (change: -45%)\n",
    "```\n",
    "\n",
    "### **Step 3: Measure importance**\n",
    "- **\"excellent\"** causes the biggest drop â†’ **most important word** (45% impact)\n",
    "- **\"The\"** causes tiny drop â†’ low importance (1% impact)\n",
    "\n",
    "### **Key Insight:**\n",
    "> **The more the prediction changes when a word is removed, the more important that word is.**\n",
    "\n",
    "This technique is called **leave-one-out** or **ablation** analysis. It's simple but effective!\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§± **Building a Sentiment Classifier**\n",
    "\n",
    "We'll use the simplest possible sentiment classifier:\n",
    "- **Model:** Logistic Regression\n",
    "- **Features:** TF-IDF word embeddings\n",
    "- **Training data:** 12 labeled movie reviews\n",
    "- **Training time:** <0.1 seconds\n",
    "\n",
    "This isn't state-of-the-art, but it's perfect for understanding saliency!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (runs silently)\n",
    "!pip install scikit-learn matplotlib numpy -q\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "print(\"âœ“ Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Create Training Data**\n",
    "\n",
    "We'll use a tiny corpus of 12 movie reviewsâ€”just enough to train a simple classifier.\n",
    "\n",
    "Notice the mix of:\n",
    "- Clear sentiment words (\"excellent\", \"terrible\", \"disappointing\")\n",
    "- Negations (\"not good\")\n",
    "- Mixed sentiments (\"surprisingly good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training corpus: 12 movie reviews\n",
    "reviews = [\n",
    "    # Positive reviews\n",
    "    \"The movie was surprisingly good and the acting was excellent.\",\n",
    "    \"I loved the beautiful scenery and compelling story.\",\n",
    "    \"Outstanding performances from the entire cast.\",\n",
    "    \"A masterpiece of cinema with brilliant direction.\",\n",
    "    \"Absolutely fantastic film that exceeded my expectations.\",\n",
    "    \"Wonderful experience, highly recommend to everyone.\",\n",
    "    \n",
    "    # Negative reviews\n",
    "    \"The plot was boring and the pacing was terrible.\",\n",
    "    \"Worst film I have seen, completely disappointing.\",\n",
    "    \"The acting was mediocre and the story made no sense.\",\n",
    "    \"Terrible movie with poor writing and weak performances.\",\n",
    "    \"Boring dialogue and predictable plot twists throughout.\",\n",
    "    \"The movie was not good at all, very disappointing.\"\n",
    "]\n",
    "\n",
    "# Labels: 1 = positive, 0 = negative\n",
    "labels = [1, 1, 1, 1, 1, 1,  # first 6 positive\n",
    "          0, 0, 0, 0, 0, 0]  # last 6 negative\n",
    "\n",
    "print(f\"Training data: {len(reviews)} reviews\")\n",
    "print(f\"  Positive: {sum(labels)}\")\n",
    "print(f\"  Negative: {len(labels) - sum(labels)}\")\n",
    "print(\"\\nExample positive review:\")\n",
    "print(f\"  '{reviews[0]}'\")\n",
    "print(\"\\nExample negative review:\")\n",
    "print(f\"  '{reviews[6]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Train the Sentiment Classifier**\n",
    "\n",
    "We'll create a simple pipeline:\n",
    "1. **TF-IDF Vectorizer:** Converts text to numerical features\n",
    "2. **Logistic Regression:** Learns to classify sentiment\n",
    "\n",
    "This trains instantly on our tiny dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "model = make_pipeline(\n",
    "    TfidfVectorizer(max_features=100, ngram_range=(1, 1)),\n",
    "    LogisticRegression(max_iter=1000, random_state=42)\n",
    ")\n",
    "\n",
    "model.fit(reviews, labels)\n",
    "\n",
    "# Test on training data (just to see it works)\n",
    "train_accuracy = model.score(reviews, labels)\n",
    "print(f\"\\nâœ“ Model trained successfully!\")\n",
    "print(f\"Training accuracy: {train_accuracy*100:.1f}%\")\n",
    "print(\"\\nNote: This is on training data onlyâ€”this is just a demonstration!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3: Test the Classifier on Example Sentences**\n",
    "\n",
    "Let's see what our model predicts for some test sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sentences\n",
    "test_sentences = [\n",
    "    \"This movie was excellent and I loved it.\",\n",
    "    \"The film was terrible and boring.\",\n",
    "    \"It was not good at all.\",\n",
    "    \"Outstanding performances from the cast.\"\n",
    "]\n",
    "\n",
    "print(\"Model predictions on test sentences:\\n\")\n",
    "for sentence in test_sentences:\n",
    "    prob = model.predict_proba([sentence])[0]\n",
    "    sentiment = \"POSITIVE\" if prob[1] > 0.5 else \"NEGATIVE\"\n",
    "    confidence = max(prob) * 100\n",
    "    print(f\"Sentence: '{sentence}'\")\n",
    "    print(f\"  â†’ {sentiment} ({confidence:.1f}% confidence)\")\n",
    "    print(f\"  â†’ P(positive) = {prob[1]:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ” **Computing Word Importance via Masking**\n",
    "\n",
    "Now comes the interesting part: **which words matter most** for these predictions?\n",
    "\n",
    "We'll implement the masking approach we discussed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_word_importance(sentence, model):\n",
    "    \"\"\"\n",
    "    Compute importance of each word by measuring prediction change when word is removed.\n",
    "    \n",
    "    Args:\n",
    "        sentence: Input text string\n",
    "        model: Trained sklearn pipeline\n",
    "    \n",
    "    Returns:\n",
    "        words: List of words in sentence\n",
    "        importance: List of importance scores (positive = contributes to positive sentiment)\n",
    "    \"\"\"\n",
    "    # Get baseline prediction (probability of positive class)\n",
    "    baseline_prob = model.predict_proba([sentence])[0][1]\n",
    "    \n",
    "    # Split sentence into words\n",
    "    words = sentence.split()\n",
    "    importance = []\n",
    "    \n",
    "    # Remove each word one at a time\n",
    "    for i in range(len(words)):\n",
    "        # Create masked sentence (remove word i)\n",
    "        masked_words = words[:i] + words[i+1:]\n",
    "        \n",
    "        if len(masked_words) == 0:\n",
    "            # Edge case: single word sentence\n",
    "            importance.append(baseline_prob)\n",
    "        else:\n",
    "            masked_sentence = ' '.join(masked_words)\n",
    "            masked_prob = model.predict_proba([masked_sentence])[0][1]\n",
    "            \n",
    "            # Importance = how much prediction changed\n",
    "            # Positive value â†’ word contributes to positive sentiment\n",
    "            # Negative value â†’ word contributes to negative sentiment\n",
    "            importance.append(baseline_prob - masked_prob)\n",
    "    \n",
    "    return words, importance\n",
    "\n",
    "print(\"âœ“ Word importance function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4: Visualize Word Importance**\n",
    "\n",
    "Let's create a function to visualize which words matter most:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_word_importance(sentence, model, figsize=(12, 4)):\n",
    "    \"\"\"\n",
    "    Visualize word importance as a bar chart.\n",
    "    \"\"\"\n",
    "    words, importance = compute_word_importance(sentence, model)\n",
    "    \n",
    "    # Get baseline prediction\n",
    "    baseline_prob = model.predict_proba([sentence])[0][1]\n",
    "    sentiment = \"POSITIVE\" if baseline_prob > 0.5 else \"NEGATIVE\"\n",
    "    \n",
    "    # Create bar chart\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Color bars: green for positive contribution, red for negative\n",
    "    colors = ['green' if imp > 0 else 'red' for imp in importance]\n",
    "    \n",
    "    ax.bar(range(len(words)), importance, color=colors, alpha=0.7)\n",
    "    ax.set_xticks(range(len(words)))\n",
    "    ax.set_xticklabels(words, rotation=45, ha='right')\n",
    "    ax.set_ylabel('Importance Score', fontsize=12)\n",
    "    ax.set_title(f'Word Importance for Sentiment Prediction\\n\"{sentence}\"\\nPrediction: {sentiment} ({baseline_prob*100:.1f}% positive)', \n",
    "                 fontsize=12, pad=20)\n",
    "    ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print top words\n",
    "    word_scores = list(zip(words, importance))\n",
    "    word_scores.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    \n",
    "    print(f\"\\nTop 3 most important words:\")\n",
    "    for word, score in word_scores[:3]:\n",
    "        direction = \"positive\" if score > 0 else \"negative\"\n",
    "        print(f\"  '{word}': {score:+.3f} (contributes to {direction} sentiment)\")\n",
    "\n",
    "print(\"âœ“ Visualization function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“Š **Example 1: Positive Review**\n",
    "\n",
    "Let's analyze a clearly positive sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = \"The movie was excellent and the acting was brilliant.\"\n",
    "visualize_word_importance(example1, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **What to Notice:**\n",
    "- **\"excellent\"** and **\"brilliant\"** likely have the highest importance (green bars)\n",
    "- **\"The\"**, **\"was\"**, **\"and\"** likely have very low importance (short bars)\n",
    "- The bars point **upward** (positive contribution to positive sentiment)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“ **Question 4 (Observation)**\n",
    "\n",
    "**Q4.** In the example sentence above, which word had the highest importance score? Does this match your intuition?\n",
    "\n",
    "*Record your answer in the Answer Sheet.*\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Š **Example 2: Negative Review**\n",
    "\n",
    "Now let's analyze a negative sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example2 = \"The plot was boring and the acting was terrible.\"\n",
    "visualize_word_importance(example2, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **What to Notice:**\n",
    "- **\"boring\"** and **\"terrible\"** likely have large **negative** scores (red bars pointing down)\n",
    "- This means removing them would make the sentence **less negative**\n",
    "- Function words again have low importance\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Š **Example 3: Negation (Tricky Case)**\n",
    "\n",
    "What happens when we use negation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example3 = \"The movie was not good at all.\"\n",
    "visualize_word_importance(example3, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **What to Notice:**\n",
    "- **\"not\"** might have high importance because it flips the sentiment!\n",
    "- **\"good\"** might actually contribute **positively**, but \"not\" negates it\n",
    "- This shows a limitation of simple word-level saliencyâ€”it doesn't capture interactions\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“ **Question 6 (Experimentation)**\n",
    "\n",
    "**Q6.** What happens when you mask a negation word like \"not\"? (Look at Example 3 above or try your own in the interactive section below)\n",
    "\n",
    "*Think about: If you remove \"not\" from \"The movie was not good\", what happens to the sentiment prediction? Why is \"not\" so important?*\n",
    "\n",
    "*Record your answer in the Answer Sheet.*\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ® **Interactive: Try Your Own Sentences!**\n",
    "\n",
    "Now it's your turn! Enter your own sentences and see which words the model finds important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own sentence here!\n",
    "# Change this to any sentence you want:\n",
    "\n",
    "my_sentence = \"This film was surprisingly wonderful and exceeded all expectations.\"\n",
    "\n",
    "print(f\"Analyzing: '{my_sentence}'\\n\")\n",
    "visualize_word_importance(my_sentence, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“ **Question 5 (Experimentation)**\n",
    "\n",
    "**Q5.** Try your own sentence in the interactive section above. Which words were most important? \n",
    "\n",
    "Record:\n",
    "- **Your sentence:** _____________________________________\n",
    "- **Top 3 important words:**\n",
    "  1. _____________ (importance: _____)\n",
    "  2. _____________ (importance: _____)\n",
    "  3. _____________ (importance: _____)\n",
    "\n",
    "*Record your results in the Answer Sheet.*\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ¤” **Understanding the Results**\n",
    "\n",
    "Let's explore what we learned about word importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze several sentences to find patterns\n",
    "test_cases = [\n",
    "    \"excellent film\",\n",
    "    \"terrible movie\",\n",
    "    \"the movie\",\n",
    "    \"it was good\",\n",
    "    \"it was not good\"\n",
    "]\n",
    "\n",
    "print(\"Comparing word importance across different sentence structures:\\n\")\n",
    "for sentence in test_cases:\n",
    "    words, importance = compute_word_importance(sentence, model)\n",
    "    prob = model.predict_proba([sentence])[0][1]\n",
    "    \n",
    "    print(f\"'{sentence}'\")\n",
    "    print(f\"  Prediction: {prob*100:.1f}% positive\")\n",
    "    for word, imp in zip(words, importance):\n",
    "        print(f\"    '{word}': {imp:+.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Key Patterns:**\n",
    "\n",
    "1. **Content words matter most:** \"excellent\", \"terrible\", \"good\", \"bad\"\n",
    "2. **Function words matter least:** \"the\", \"was\", \"it\"\n",
    "3. **Negations are crucial:** \"not\" flips sentiment entirely\n",
    "4. **Context matters:** \"good\" by itself is positive, but \"not good\" is negative\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“ **Question 7 (Analysis)**\n",
    "\n",
    "**Q7.** Why might function words like \"the\" and \"and\" have low importance scores?\n",
    "\n",
    "*Think about: What information do these words provide? Do they carry sentiment?*\n",
    "\n",
    "*Record your answer in the Answer Sheet.*\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”— **Connection to Real-World Applications**\n",
    "\n",
    "Word saliency has practical applications:\n",
    "\n",
    "### **Debugging Text Classifiers**\n",
    "- **Problem:** Your spam filter marks legitimate emails as spam\n",
    "- **Solution:** Use saliency to see which words triggered the flag\n",
    "- **Discovery:** The model focuses on \"click here\" and \"free\"â€”even in legitimate contexts!\n",
    "- **Action:** Retrain with more diverse examples\n",
    "\n",
    "### **Detecting Bias**\n",
    "- **Problem:** A resume screener might be biased\n",
    "- **Solution:** Use saliency to see which words affect hiring decisions\n",
    "- **Discovery:** Names, universities, and graduation years have high saliency\n",
    "- **Action:** Remove identifying information, focus on skills\n",
    "\n",
    "### **Content Moderation**\n",
    "- **Problem:** Users complain about false positives in hate speech detection\n",
    "- **Solution:** Use saliency to understand which words triggered the flag\n",
    "- **Discovery:** Certain words are flagged even in neutral contexts\n",
    "- **Action:** Improve context understanding, reduce false positives\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“ **Question 8 (Application)**\n",
    "\n",
    "**Q8.** How could word saliency be useful for debugging a text classifier in a real-world application?\n",
    "\n",
    "*Think about: What problems might saliency reveal? How could you use this information to improve the model?*\n",
    "\n",
    "*Record your answer in the Answer Sheet.*\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Module 1 Complete!\n",
    "\n",
    "You've learned:\n",
    "- **How to compute word importance** using masking/ablation\n",
    "- **Which words drive sentiment predictions** (content words >> function words)\n",
    "- **How negations affect importance** (\"not\" flips sentiment)\n",
    "- **Why saliency is useful** for debugging and bias detection\n",
    "\n",
    "**Key Insight:** Saliency reveals **which features** drive predictions, helping us understand and improve models.\n",
    "\n",
    "**Next up:** Module 2, where you'll explore **image saliency**â€”seeing which pixels matter most for object recognition!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
